
\فصل{روش‌های پیشنهادی و نتایج}

\قسمت{مقدمه}
در این فصل به معرفی روش‌های ارایه شده در این مطالعه، برای قطعه‌بندی ساختارهای در ریسک و تومور با استفاده از شبکه‌های عصبی عمیق پرداخته خواهد شد. مطالعه شامل دو بخش است که در بخش اول به قطعه‌بندی ساختارهای در ریسک، چالش‌های موجود، راهکارهای پیشنهادی و ارزیابی روش‌های پیشنهادی پرداخه می‌شود و در بخش دوم مطالعه همین روند برای قطعه‌بندی تومور طی خواهد شد.

\قسمت{روش‌های پیشنهادی قطعه‌بندی ساختارهای در ریسک}

همانطور که در فصل اول اشاره گردید، ضرورت قطعه‌بندی ساختارهای در ریسک، در تهیه‌ی نقشه‌ی درمان برای رادیوتراپی است. این نقشه‌ی درمان کمک می‌کند تا به بافت‌های سالم کنار تومور (ساختارهای در ریسک) کمترین آسیب و تومور بیشترین دوز پرتو را دریافت کند. بنابراین لازم است این ساختارها با دقت  و سرعت بالا قطعه‌بندی شوند و در روند درمان قرار گیرند. این قطعه‌بندی به صورت دستی زمان‌بر، پرهزینه (هزینه‌ی استخدام شخص متخصص)، خسته‌کننده و متغیر بر اساس دیدگاه هر متخصص است.

بنابراین برای تسریع این روند و حل مشکلات ذکر شده، روش‌های خودکار و نیمه‌-خودکار فراوانی ارایه گردید که در فصل قبل به بررسی هر یک پرداخته شد. ملاحظه گردید که الگوریتم‌های کلاسیک ارایه شده، در اکثر موارد توانایی قطعه‌بندی چند ساختار به صورت همزمان را ندارند و علاوه بر آن در اکثر موارد نیاز به یک مقدار (کانتور) اولیه دارند که این کاستی‌ها در کنار دقت پایین باعث محبوبیت پایین این روش‌ها شده است.

در دست دیگر، روش‌های قطعه‌بندی مبتنی بر یادگیری عمیق بررسی شد که با آموزش این مدل‌ها بر اساس یک مجموعه داده، علاوه بر سرعت و دقت بالا نسبت به روش‌های قطعه‌بندی کلاسیک و دستی، امکان قطعه‌بندی خودکار چند ساختار نیز وجود دارد. بنابراین شاهد استفاده‌ی روز افزون این روش‌ها و افزایش اعتبار و محبوبیت آن‌ها برای استفاده در نرم‌افزارهای قطعه‌بندی ساختارهای در ریسک در مراکز پرتو درمانی هستیم.

در این بخش به توضیح روش‌های پیشنهادی برای قطعه‌بندی ساختارهای در ریسک  بر اساس مدل‌های یادگیری عمیق پرداخته می‌شود. ابتدا مجموعه دادگان و پیش‌پردازش‌های انجام شده، توضیح داده خواهد شد و در ادامه، روش‌های پیشنهادی معرفی می‌شوند و نتایج این روش‌ها بررسی خواهد شد.

\زیرقسمت{معرفی مجموعه دادگان و پیش‌‌پردازش}
\label{segthor}
در این قسمت، دو مجموعه داده‌ برای قطعه‌بندی ساختارهای در ریسک معرفی می‌شود که در ادامه به بررسی هر یک و پیش‌پردازش‌های انجام شده، پرداخته خواهد شد.
\زیرزیرقسمت{مجموعه داده‌ی SegTHOR}

مجموعه داده‌ی SegTHOR شامل قطعه‌بندی چهار ساختار در ریسک قفسه‌ی سینه در تصاویر سی‌تی اسکن است\LTRfootnote{َSegmentation of THoracic Organs at Risk}. این مجموعه تصاویر، از 40 بیمار دارای سرطان ریه و مری گرفته شده است و شامل قطعه‌بندی دستی چهار ساختار در ریسک قلب\LTRfootnote{Heart} ،آئورت\LTRfootnote{Aorta}، نای\LTRfootnote{Trachea} و مری\LTRfootnote{Esophagus} است که به عنوان استاندارد مطلوب\LTRfootnote{Ground Truth} برای آموزش شبکه‌های عصبی تهیه شده است.

این مجموعه داده برای قطعه‌بندی ساختارهای در ریسک به دلیل تغییر شکل ساختار‌های در ریسک (مانند مری) در هر شخص و نیز اختلاف شدت پایین در میان بافت‌های نرم در تصاویر سی‌تی اسکن، بسیار پر چالش است \مرجع{lambert2020segthor}.

این تصاویر دارای ابعاد اولیه‌ی $512\times512\times(150\sim 284)$ و با فاصله‌ی واکسلی\LTRfootnote{Voxel Spacing}،
 $(0.97\sim1.36)\times(0.97\sim1.36)\times(2\sim2.5)$
 در راستاهای x، y و z است که حاکی از متفاوت بودن دستگاه‌های تصویر برداری در این مجموعه دادگان است. بنابراین لازم است برای تمایز هرچه بهتر بافت‌ها و یکسان‌سازی تصاویر دستگاه‌های مختلف در جهت آموزش شبکه‌ی عصبی عمیق، یک پیش‌پردازش مناسب صورت گیرد.
 
اولین گام در پیش‌پردازش یکسان‌سازی فاصله‌ی واکسلی به $0.97\times0.97\times2$ است که با استفاده از درون‌یابی برای تصویر اصلی و تصویر قطعه‌بندی متناظر این کار انجام گردید و تا حدی تفاوت تصویربرداری در بین دستگاه‌های مختلف یکسان‌سازی شد. در گام دوم، ناحیه‌ی شامل ساختارهایی که باید قطعه‌بندی شوند از تصویر اصلی استخراج گردید و سایر نواحی مانند قسمت‌های شکمی و سر و گردن حذف شد. در گام سوم مقدار \LTRfootnote{Hounsfield Unit}HU در تصاویر اصلی که در بازه‌ی $(-1000\sim 13000)$ بود مقادیری که در خارج از بازه‌ی $(-800\sim 400)$ بود، به سقف و کف این بازه تبدیل داده شد و مقادیر این بازه در تصاویر اصلی بین صفر و یک نرمالیزه گردید. در نهایت فضاهای خالی اطراف تصویر به مرکزیت آن بریده شد و ابعاد $512\times512$ به $384\times288$ کاهش یافت. نمودار بلوکی این روند در شکل ~\رجوع{شکل:پریبلوکدیاگرام} نشان داده شده است.
\شروع{شکل}[H]
\centerimg{04segthorprepblock.png}{16cm}
\شرح{نمودار بلوکی گام‌های پیش‌پردازش بر روی دادگان}
\برچسب{شکل:پریبلوکدیاگرام}
\پایان{شکل}

شکل زیر یک نمونه تصویر از مجموعه دادگان را بعد از پیش‌پردازش نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{04segthorprepimg.png}{8cm}
\شرح{نمونه‌ی یک تصویر سی‌تی اسکن از مجموعه داده‌ی SegTHOR بعد از پیش‌پردازش، در سه نمای اکسیال، کرونال و سجیتال}
\برچسب{شکل:سگتورپیریپراسسد}
\پایان{شکل}

برای حفظ تناظر یک به یک بین تصاویر اصلی و قطعه‌بندی استاندارد، تغییرات و پردازش‌های اعمال شده در بالا، مطابق با ماهیت برچسب‌ها، اعمال گردید تا دوباره ماسک‌های قطعه‌بندی شده در روند آموزش قابل استفاده گردند. شکل ~\رجوع{شکل:سگتورویتلیبل} نمونه‌ای از تصویر اصلی همراه با برچسب‌های چهار ساختار در ریسک را نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{04segthorprepimg_withlabel.png}{8cm}
\شرح{نمونه‌ی یک تصویر سی‌تی اسکن از مجموعه داده‌ی SegTHOR بعد از پیش‌پردازش همراه با برچسب ساختار در ریسک، در چهار نمای اکسیال، کرونال، سجیتال و سه‌بعدی}
\برچسب{شکل:سگتورویتلیبل}
\پایان{شکل}

برای آموزش شبکه (شبکه‌ها به صورت دوبعدی آموزش داده می‌شوند) و افزایش قدرت تعمیم‌پذیری آن از روش افزایش مجموعه دادگان استفاده شد که در اینجا به معرفی جزییات آن پرداخته می‌شود. هر تصویر به صورت دو بعدی و از نمای اکسیال از تصویر سه‌بعدی پردازش شده با برچسب ساختارهای در ریسک متناظر استخراج می‌گردد و با اعمال تبدیلات دوران تصادفی بین زاویه‌ی $(-5,5)$ درجه، بزرگ‌نمایی و کوچک‌نمایی با ضرایب $1.1$ و $0.9$ و قرینه‌ی افقی تعداد دادگان آموزش افزایش می‌یابد. در شکل ~\رجوع{شکل:سگتوراگمنت} (الف) تصویر دوبعدی اصلی با برچسب‌ متناظر نشان داده شده است و در (ب) قرینه‌ی افقی و بزرگ‌نمایی آن با ضریب $1.1$ به تصویر کشیده شده‌است.

\شروع{شکل}[H]
\centerimg{04segthoraugmentation.png}{8cm}
\شرح{نمونه‌ی یک تصویر در نمای اکسیال با برچسب ساختار در ریسک متناظر (الف) تصویر اصلی (ب) تصویر تبدیل یافته برای افزایش دادگان}
\برچسب{شکل:سگتوراگمنت}
\پایان{شکل}

\زیرزیرقسمت{مجموعه داده‌ی قطعه‌بندی هیپوکامپ}

هیپوکامپ\LTRfootnote{Hippocampus} ساختمان عصبی خمیده‌ای است در مغز که در میانه‌ی بطن‌های طرفی مغز قرار دارد. هیپوکامپ در اعماق لوب گیجگاهی جای گرفته‌است و از دو شاخ منحنی‌وار تشکیل شده‌است که از بخش‌های مهم مغز پستانداران است. حافظه افرادی که هیپوکامپ آنان آسیب دیده یا با جراحی برداشته شده، دچار اختلال جدی می‌شود. هیپوکامپ تثبیت‌کننده میان حافظه کوتاه‌مدت و بلندمدت است و مغز قدامی را از آزموده‌های گذشته ما آگاه می‌کند. این مجموعه خاطرات گذشته را به شکل کوتاه‌مدت یا درازمدت حفظ می‌کند \مرجع{martin2003lymbic}. 

بنابراین این عضو نیز از ساختارهای مهم و حیاتی است و لازم است در طی پرتو درمانی تومورهای مغزی، این ساختار نیز به عنوان ساختار در ریسک، قطعه‌بندی شود و از آسیب به آن جلوگیری شود. مجموعه داده‌ی عمومی قطعه‌بندی تصاویر پزشکی Decathlon \مرجع{simpson2019large} شامل 260 تصویر سه‌بعدی ام‌آرای T1-weighted است که دو بخش سر و بدن هیپوکامپ را به صورت دستی و به عنوان قطعه‌بندی مطلوب ارایه داده است. ابعاد تصاویر در بازه‌ی 
$(31\sim43)\times(40\sim59)\times(24\sim47)$
و با فاصله‌ی واکسلی یک میلی‌متر هستند. 

برای پیش‌پردازش این دادگان ابتدا برای همسان‌سازی اندازه، تمام ابعاد با اضافه کردن صفر\LTRfootnote{Zero Padding} به اندازه‌ی $48\times64\times48$ تغییر داده شد. در گام‌ بعدی برای نرمالیزه کردن تصاویر از هیستوگرام تصویر کمک گرفته شد و با تقسیم مقادیر به شدت 95 درصد هیستوگرام تجمعی این نرمال‌سازی صورت گرفت. دلیل این‌کار و استفاده نکردن از مقدار بیشینه مقاوم کردن نرمال‌سازی نسبت به نویزهای با مقدار بالا در تصاویر ام‌آرآی است. در گام آخر پیش‌پردازش برچسب‌های دو قسمت هیپوکامپ، برای ایجاد یک برچسب در قطعه‌بندی با یکدیگر ترکیب شدند (در ادامه خواهیم دید از این برچسب‌ها برای یک تابع هزینه‌ی خاص استفاده شده است و لازم است ساختار پیوسته باشد). شگل ~\رجوع{شکل:هیپوپیری} تصویر قبل (الف) و بعد از پیش‌پردازش (ب) هیپوکامپ را با قطعه‌بندی متناظر نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{04hippocampusprep.png}{16cm}
\شرح{نمونه‌ی یک تصویر ام آرآی هیپوکامپ در نماهای مختلف با قطعه‌بندی (الف) تصویر اصلی (ب) تصویر پس از پیش‌پردازش}
\برچسب{شکل:هیپوپیری}
\پایان{شکل}

\زیرقسمت{آموزش قطعه‌بندی با استفاده از متد چگالش دانش}

با ظهور روش‌های یادگیری عمیق و افزایش سرعت پردازش‌گرها،امکان تعریف مدل‌های بسیار پیچیده با تعداد پارامترهای قابل یادگیری بسیار زیاد فراهم گردید. بنابراین، این مدل‌های پیچیده، توانایی استخراج ویژگی‌های سطح بالا و در نتیجه مستعد اخذ دقت بالاتر هستند. اما از طرفی گران بودن دستگاه‌های با قدرت پردازش‌ بالا و نیز محدودیت استفاده‌ی آن‌ها توجهات را به سمت انتقال دانش از مدل‌های پیچیده به سمت مدل‌های ساده‌تر جلب کرد. این کار باعث می‌شود، ویژگی‌هایی که مدل بسیار پیچیده توانایی استخراج‌ آن‌ها را دارد به مدل ساده‌تر منتقل شود و علاوه بر بدست آوردن دقت نزدیک به مدل پیچیده، هزینه‌های محاسباتی نیز کمتر شود \مرجع{cheng2018model}.

یکی از این روش‌ها چگالش دانش\LTRfootnote{Knowledge Distillation} از مدل پیچیده (آموزگار\LTRfootnote{Teacher}) به مدل ساده (دانش‌آموز\LTRfootnote{Student}) است که در ادامه قصد داریم این روش را در قطعه‌بندی ساختارهای در ریسک استفاده کنیم و مدل‌های ساده‌تر برای این قطعه‌بندی را به دقت‌های بالاتر بدون تغییر هزینه‌های محاسباتی برسانیم.

\زیرزیرقسمت{چگالش دانش}

چگالش دانش از یادگیری انسان اقتباس شده‌است که یک آموزگار که در یک موضوع مسلط است به دانش‌آموز آموزش می‌دهد. بنابراین چارچوب چگالش دانش را می‌توان شامل یک یا چند مدل بزرگ از پیش آموزش دیده شده و یک مدل ضعیف تعریف کرد که ایده‌ی اصلی آن آموزش مدل ضعیف‌تر (دانش‌آموز) با نظارت مدل پیچیده (آموزگار) برای رسیدن به دقت قابل مقایسه با آموزگار است.

سیگنال نظارتی که از مدل آموزگار به دانش‌آموز می رسد را	 \مهم{دانش} می‌نامیم که قبلا توسط آموزگار یادگرفته شده است و دانش‌آموز سعی در تقلید رفتار آموزگار در یادگیری دانش را دارد. به عنوان مثال در یک مساله‌ی طبقه‌بندی تصاویر، لاجیت‌ها\LTRfootnote{Logits}(خروجی آخرین لایه در شبکه‌های عصبی عمیق) به عنوان حامل‌های دانش از مدل آموزگار به مدل دانش‌آموز استفاده می‌شود که این دانش توسط برچسب‌های صحیح مطلوب تامین نمی شود. برای فهم بیشتر این مطلب، فرض کنید یک مساله‌ی طبقه‌بندی بین چهار طبقه‌ی گاو، سگ، گربه و ماشین وجود دارد. در نهایت بعد از آموزش یک مدل بر روی این دادگان دو نوع خروجی نرم و سخت\LTRfootnote{Soft and Hard Targets} در دسترس است. خروجی‌های سخت مربوط به برچسب‌های مطلوب است و خروجی‌های نرم مربوط به احتمالات پیش‌بینی شده برای هر طبقه، توسط مدل است. با توجه به شکل ~\رجوع{شکل:هاردسافتتارگت} و مقادیری که برای پیش‌بینی یک تصویر به عنوان سگ شده است می‌توان دریافت علاوه بر پیش‌بینی با احتمال بالا برای کلاس صحیح، میزان مشابهت با کلاس‌های دیگر نیز در خروجی‌های نرم وجود دارد. به عنوان مثال به علت شباهت زیاد سگ و گربه مقدار $0.1$ برای این شباهت بدست آمده است اما در مقایسه با کلاس‌های ماشین و گاو، کلاس گاو نسبت به کلاس ماشین به علت حیوان و چهارپا بودن هر دو (سگ و گاو) احتمال بیشتری نسبت داده شده است. بنابراین در این نوع خروجی‌ها اطلاعات بیشتری نسبت به خروجی‌های سخت وجود دارد \مرجع{liu2018improving}.

\شروع{شکل}[H]
\centerimg{04softvshardtargets.png}{8cm}
\شرح{خروجی‌های سخت و نرم برای طبقه‌بندی چهار کلاس \مرجع{liu2018improving}}
\برچسب{شکل:هاردسافتتارگت}
\پایان{شکل}

برای بدست آوردن احتمال حضور در i امین طبقه، لاجیت‌ها را از یک تابع فعالیت Softmax عبور می‌دهند تا این احتمال با مقدار $p_i$ مشخص شود. معادله‌ی ~\رجوع{softmax} تابع فعالیت Softmax را نشان می‌دهد.

\begin{alignat}{5}
	p_i = \frac{exp(z_i)}{\Sigma_j exp(z_j)}    \label{softmax} 
\end{alignat}

برای استخراج خروجی‌های نرم، با اضافه کردن یک فاکتور دما\LTRfootnote{Temperature Factor}(T) به معادله‌ی Softmax می‌توان این خروجی‌ها را استخراج کرد. با افزایش مقدار فاکتور دما میزان نرم‌ شدن خروجی‌ها بیشتر می‌شود و با کاهش آن مقدار خروجی‌ها به خروجی‌های سخت نزدیک‌تر می‌شود. بنابراین با این فاکتور می‌توان میزان اهمیت هر برچسب را نرم را کنترل کرد. معادله‌ی زیر چگونگی اعمال فاکتور دما در معادله‌ی Softmax را نشان می‌دهد.

\begin{alignat}{5}
	p_i = \frac{exp(z_i/T)}{\Sigma_j exp(z_j/T)}    \label{softsoftmax} 
\end{alignat}

خروجی‌های نرم در مدل‌های آموزگار و دانش‌آموز و نیز خروجی‌های مطلوب\LTRfootnote{Ground Truth} نقش مهمی در آموزش دانش‌آموز دارند و با داشتن این مقادیر می‌توان تابع‌ هزینه‌ی مربوط به چگالش دانش\LTRfootnote{Distillation Loss} و 
تابع هزینه‌ی دانش‌آموز\LTRfootnote{Student Loss} را تعریف نمود. تابع هزینه‌ی چگالش دانش را می‌توان به صورت زیر میان لاجیت‌های آموز‌گار و دانش‌آموز به صورت یک تابع هزینه‌ی \lr{Cross-Entropy} نوشت. 

\begin{alignat}{5}
	L_D(p(z_t,T), p(z_s,T)) = -\Sigma_i p_i(z_{ti},T) \log(p_i(z_{si},T))    \label{ld} 
\end{alignat}

که در آن $z_t$ و $z_s$ به ترتیب، لاجیت‌های آموزگار و دانش‌آموز هستند. گرادیان تابع‌ هزینه‌ی چگالش نسبت به لاجیت‌های دانش‌آموز می‌تواند به صورت زیر محاسبه گردد.

\begin{alignat}{5}
	\frac{\partial L_D(p(z_t,T), p(z_s,T))}{\partial z_{si}} = \frac{p(z_t,T) - p(z_s,T)}{T}    
	= \frac{1}{T}(\frac{exp(z_{si}/T)}{\Sigma_j exp(z_{sj}/T)}  -\frac{exp(z_{ti}/T)}{\Sigma_j exp(z_{tj}/T)}) \label{gradld}
\end{alignat}

اگر فاکتور دما (T) بسیار بزرگتر از مقدار لاجیت‌ها باشد آنگاه با استفاده از بسط تیلور معادله‌ی ~\رجوع{gradld} را می‌توان به صورت زیر بازنویسی نمود.
\begin{alignat}{5}
	\frac{\partial L_D(p(z_t,T), p(z_s,T))}{\partial z_{si}} = \frac{1}{T}(\frac{1+\frac{z_{si}}{T}}{N+\Sigma_j \frac{z_{sj}}{T}} - \frac{1+\frac{z_{ti}}{T}}{N+\Sigma_j \frac{z_{tj}}{T}})    
	\label{gradsimplelddd}
\end{alignat}

با فرض میانگین صفر بودن لاجیت‌های آموزگار و دانش آموز معادله‌ی فوق را می‌توان ساده‌تر نمود.
\begin{alignat}{5}
	\frac{\partial L_D(p(z_t,T), p(z_s,T))}{\partial z_{si}} = \frac{1}{NT^2}(z_{si}-z_{ti})    
	 \label{gradsimpleld}
\end{alignat}

بنابراین با توجه به معادله‌ی ~\رجوع{gradsimpleld} هدف تابع هزینه‌ی چگالش، کمینه کردن فاصله‌ی میان لاجیت‌های آموزگار و شاگرد است \مرجع{hinton2015distilling}. تابع هزینه‌ی دانش‌آموز را نیز می‌توان به صورت \lr{Cross-Entropy} بین خروجی مطلوب و لاجیت‌های دانش‌آموز به صورت زیر نوشت.
\begin{alignat}{5}
	L_S(y, p(z_s,T)) = -\Sigma_i y \log(p_i(z_{si},T))    \label{ls} 
\end{alignat}

در نهایت، با کنار هم قرار دادن تابع‌ هزینه‌‌ی چگالش و تابع هزینه‌ی دانش‌آموز، تابع هزینه‌ی کلی برای چارچوب چگالش دانش از آموزگار به شاگرد طبق معادله‌ی ~\رجوع{losstotal} تشکیل می‌شود که با ضریب $\alpha$ مجموع این دو تابع به صورت وزن‌دار محاسبه می‌شود.

\begin{alignat}{5}
	L_{TotalDistillation} = \alpha L_D(p(z_t,T), p(z_s,T)) + (1-\alpha) L_S(y, p(z_s,T))   \label{losstotal} 
\end{alignat}

فاکتور دمای T در تابع هزینه‌ی دانش‌آموز برابر با یک و در تابع‌ هزینه‌ی چگالش برابر یا بزرگتر از یک در نظر گرفته می‌شود. بنابراین به صورت کلی، چارچوب چگالش دانش را می‌توان به صورت شکل ~\رجوع{شکل:نالجدیس} بیان نمود که در آن، آموزگار یک مدل از پیش آموزش دیده شده‌است و دانش‌آموز به واسطه‌ی خروجی‌های نرم و مقادیر مطلوب که دو تابع هزینه را تشکیل می‌دهند، آموزش داده می‌شود \مرجع{gou2021knowledge}.

\شروع{شکل}[H]
\centerimg{04knowledgedistillationframework.png}{15cm}
\شرح{عملکرد انتقال دانش توسط چارچوب چگالش دانش \مرجع{gou2021knowledge}}
\برچسب{شکل:نالجدیس}
\پایان{شکل}


\زیرزیرقسمت{معماری شبکه‌های قطعه‌بند}

همانطور که پیش‌تر اشاره گردید، در این قسمت، قصد داریم با استفاده از چارچوب چگالش دانش در بحث قطعه‌بندی ساختارهای در ریسک استفاده کنیم. برای این‌کار نیاز به مدل‌های آموزگار و دانش‌آموز است که در ابتدا یک مدل پیچیده با توانایی بالا بر روی دادگان به عنوان آموزگار آموزش می‌بیند و سپس مدل ساده‌تر (دانش‌آموز) با استفاده از چارچوب چگالش دانش، از دانش مدل آموزگار برای بهبود عملکرد بهره می‌برد.

برای مدل آموزگار از معماری یک UNet پیچیده با تعداد پارامتر‌های قابل آموزش بالا و روش‌های تعمیم‌پذیری استفاده گردید. معماری این شبکه‌ی تمام کانوولوشنی عمیق در شکل ~\رجوع{شکل:تیچریونت} قابل مشاهده است.

\شروع{شکل}[H]
\centerimg{04teacherUnet.png}{15cm}
\شرح{معماری شبکه‌ی UNet پیچیده، استفاده شده به عنوان آموزگار}
\برچسب{شکل:تیچریونت}
\پایان{شکل}

تفاوت این معماری با معماری UNet اولیه‌ی معرفی شده در \مرجع{ronneberger2015u} استفاده از ابزارهای افزایش قدرت تعمیم‌پذیری مانند dropout و Batch-normalization پس از لایه‌های کانوولوشنی است. همچنین برای افزایش وسعت دید شبکه و استخراج ویژگی‌ها عمیق‌تر  و کلی‌تر از سطح تصویر، اندازه‌ی فیلتر‌های کانوولوشنی برابر با $13\times13$ تعریف گردید.

در ادامه، برای تعریف مدل دانش‌آموز، از دو معماری ساده‌تر استفاده شد. دانش‌آموز اول یک مدل UNet بسیار ساده‌تر با تعداد پارامترهای بسیار کمتر از UNet پیچیده‌ی آموزگار و دانش‌آموز دوم بک معماری بر اساس بلوک‌های Residual است. شکل ~\رجوع{شکل:اسوانیونت} معماری یک UNet ساده شده را به عنوان دانش‌آموز اول نشان می‌دهد که در مقایسه با معماری آموزگار در شکل ~\رجوع{شکل:تیچریونت}، ساختار ساده‌تری دارد که عبارتند از: کاهش ابعاد فیلترهای کانوولوشنی به $3\times3$ و در نتیجه کاهش وسعت دید هر فیلتر، استفاده نکردن از روش‌های تعمیم‌پذیری dropout و Batch-normalization و در نهایت کاهش تعداد ویژگی‌های استخراج شده به نصف، نسبت به UNet پیچیده. 

\شروع{شکل}[H]
\centerimg{04simpleUnet.png}{10cm}
\شرح{معماری شبکه‌ی UNet ساده، استفاده شده به عنوان دانش‌آموز اول}
\برچسب{شکل:اسوانیونت}
\پایان{شکل}

شکل ~\رجوع{شکل:استو}، معماری دانش‌آموز دوم را که بر اساس بلوک‌های Residual طراحی شده است را نشان می‌دهد. که دوباره، نسبت به مدل آموزگار، دارای تعداد ویژگی نصف در هر لایه‌ است منتها برای آموزش بهتر آن از روش Batch-normalization نیز استفاده شده است.

\شروع{شکل}[H]
\centerimg{04Resnetstudent.png}{15cm}
\شرح{معماری شبکه‌ی پیشنهادی بر اساس بلوک‌های Residual، استفاده شده به عنوان دانش‌آموز دوم}
\برچسب{شکل:استو}
\پایان{شکل}

\زیرزیرقسمت{آموزش شبکه‌های قطعه‌بند}

برای آموزش شبکه‌های معرفی شده در بالا، از مجموعه دادگان ساختارهای در ریسک قفسه‌ی سینه‌ی SegTHOR معرفی شده در بخش ~\رجوع{segthor} استفاده گردید. همانظور که گفته شد، این مجموعه داده قطعه‌بندی چهار ساختار در ریسک را در 40 تصویر سی‌تی اسکن قفسه‌ی سینه تهیه نموده است. بنابراین برای قطعه‌بندی این چهار ساختار، همانطور که در شکل‌های ~\رجوع{شکل:تیچریونت} و ~\رجوع{شکل:اسوانیونت} نشان داده شده است، در لایه‌ی خروجی این معماری‌ها چهار خروجی گرفته شده است که هر یک از آن‌ها مسوول قطعه‌بندی یکی از ساختارهاست.

برای آموزش بر اساس چارچوب چگالش دانش لازم است تابع فعالیت خروجی برای کلاس‌ها Softmax باشد که با توجه به چهار ساختار در ریسک قلب، آئورت، نای و مری یک کلاس پس‌زمینه نیز به این چهار کلاس اضافه می‌شود تا بتوان از تابع هزینه‌ی \lr{Cross-Entropy} استفاده نمود. اما با آزمایش‌های اولیه‌ای که صورت گرفت، ملاحظه گردید در نظر نگرفتن پس‌زمینه به عنوان یک کلاس مجزا و فقط قطعه‌بندی چهار ساختار در ریسک، دقت بالاتری را بوجود می‌آورد بنابراین معماری شبکه‌ها برای ایجاد خروجی، تنها برای ساختارهای در ریسک طراحی گردید.

در این حالت، مشکلی که بوجود می‌آید عدم توانایی در استفاده از تابع هزینه‌ی \lr{Cross-Entropy} است زیرا دیگر طبقه‌ی اضافی پس زمینه وجود ندارد. برای حل این مشکل از تابع هزینه‌ی \lr{Binary Cross-Entropy} استفاده شد که به صورت زیر تعریف می‌شود:

\begin{alignat}{5}
	BCE = -\frac{1}{N}\sum_{i=1}^N \sum_{k=1}^K \sum_{l=1}^L y_i(k,l) \log(p_i(k,l))+(1-y_i(k,l))  \log(1-p_i(k,l))  \label{bce} 
\end{alignat}

که در آن $y_i$ خروجی مطلوب که صفر یا یک است و $p_i$ خروجی پیش‌بینی شده است که در بازه‌ی صفر و یک است، N تعداد نمونه‌ها و K و L ابعاد تصاویر هستند. فرض کنید اگر خروجی مطلوب برابر با صفر باشد، ترم اول در معادله‌ی ~\رجوع{bce} حذف می‌شود و ترم دوم سعی می‌کند با کمینه‌کردن مقدار هزینه، مقدار پیش‌بینی شده را به صفر نزدیک کند. بنابراین با صفر بودن دایمی یکی از کلاس‌ها با استفاده از این تابع هزینه، مشکلی در یادگیری بوجود نمی‌آید و با حل کردن این مساله‌ی بهینه‌سازی برای کلاس پس‌زمینه، مقدار $0.25$ در هر یک از نقشه‌های احتمال چهار ساختار در ریسک، بدست می‌آید.

برای آموزش شبکه‌ها به صورت تصادفی 80 درصد دادگان (32 تصویر سی‌تی اسکن) به عنوان دادگان آموزش و مابقی دادگان به عنوان دادگان آزمایش جدا شدند. بنابراین با توجه به موارد گفته شده، در ابتدا مدل آموزگار با استفاده از تابع هزینه‌ی \lr{Binary Cross-Entropy} و روش بهینه‌سازی Adam و با روش افزایش داده‌ی توضیح داده شده، آموزش داده شد. سپس با توجه به چارچوب چگالش دانش، دو مدل دانش‌آموز با همان دادگان آموزشی آموزگار، آموزش دیدند.

برای آموزش، دو مدل دانش‌آموز مطابق شکل ~\رجوع{شکل:مایدیستیل} دادگان آموزش ورودی به مدل از پیش آموزش دیده‌ی آموزگار و دانش‌آموز وارد می‌شود و با دریافت لاجیت‌های خروجی هر مدل توابع هزینه‌ی چگالش و دانش‌آموز تعریف خواهد شد.

\شروع{شکل}[H]
\centerimg{04distillationframework.png}{9cm}
\شرح{آموزش شبکه‌های دانش‌آموز برمبنای چارچوب چگالش دانش از آموزگار}
\برچسب{شکل:مایدیستیل}
\پایان{شکل}

به طور معمول برای تعریف تابع هزینه‌ی چگالش بین خروجی مدل آموزگار و دانش‌آموز از فاصله‌ی
 KL \LTRfootnote{Kullback-Leibler (KL) divergence loss}
 استفاده می‌شود \مرجع{gou2021knowledge} که با معادله‌ی زیر توصیف می‌شود و سعی در کم کردن فاصله‌ی بین دو توزیع احتمال را دارد. 

\begin{alignat}{5}
	L_D(p(z_s), p(z_t)) = L_{KL}(p(z_s), p(z_t)) = \sum p(z_s) \log(\frac{p(z_s)}{p(z_t)})    \label{kldivergence} 
\end{alignat}

بنابراین با استفاده از فاصله‌ی KL به عنوان تابع هزینه‌ی چگالش دانش و تابع هزینه‌ی BCE به عنوان تابع هزینه‌ی میان پیش‌بینی دانش‌آموز و مقادیر مطلوب، هزینه‌ی کلی به صورت زیر تعریف گردید.
 
\begin{alignat}{5}
	L_{total} = \alpha BCE(p(z_s), y) + (1-\alpha)L_{KL}(p(z_s,T), p(z_t,T))     \label{bceklloss} 
\end{alignat}

با ملاحظات گفته‌شده در بالا و تنظیم پارامترهای T برابر با 2 و $\alpha$ برابر با $0.2$ آموزش دو شبکه‌ی دانش‌آموز با چارچوب چگالش دانش از آموزگار صورت گرفت. برای مقایسه‌ی عملکرد این چارچوب، مدل‌های دانش‌آموز یک‌ بار دیگر با همان دادگان آموزش برای آموزگار و شرایط یکسان منتها به صورت معمول و تنها تابع هزینه‌ی BCE آموزش داده شدند. در ادامه به بررسی نتایج حاصل پرداخته خواهد شد.

\زیرزیرقسمت{نتایج}

برای محاسبه‌ی معیارهای ارزیابی باید برچسب‌های احتمالاتی پس از تابع فعالیت Softmax آستانه‌گذاری شوند و برخلاف تابع فعالیت Sigmoid که آستانه‌ی مشخص $0.5$ را دارد، در این حالت باید آستانه‌های بهینه برای بدست آوردن بالاترین مقدار در معیارهای قطعه‌بندی استخراج گردد. برای این‌کار، پیش‌بینی‌های احتمالاتی برای مدل آموزگار، بر روی مجموعه‌ داده‌ی آموزش استخراج گردید و با آستانه‌گذاری‌های مختلف، معیار Dice برای دادگان آموزش و چهار ارگان در ریسک استخراج گردید. نمودار زیر تاثیر مقدار آستانه را بر روی مقدار معیار Dice برای هر ساختار نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{04thresholdsVSDice.png}{9cm}
\شرح{تاثیر تغییر آستانه بر روی معیار Dice برای هر ساختار در ریسک}
\برچسب{شکل:ترشولددایس}
\پایان{شکل}

همانطور که در شکل ~\رجوع{شکل:ترشولددایس} ملاحظه‌ می‌شود مقدار آستانه بهینه برای هر ساختار متفاوت است. برای استخراج این آستانه‌ی بهینه از روش آستانه‌گذاری اوتسو، که در فصل قبل توضیح داده شد، استفاده گردید، به این ترتیب آستانه‌ی بهینه برای مری، $0.71$، قلب، $0.93$، نای، $0.86$ و آئورت، $0.82$ بدست آمد. بنابراین با این آستانه‌گذاری ماسک‌های صفر و یک، برای چهار ارگان در ریسک ذکر شده بر روی دادگان آزمایش برای تمامی مدل‌ها بدست آمد. جدول‌های زیر دو معیار ارزیابی Dice و Jaccard  را برای چهار ساختار در ریسک، نشان می‌دهد. در سه ردیف نخست، ارزیابی عددی برای شبکه‌های آموزگار، دانش‌آموز Resnet (شبکه‌ی مبتنی بر بلوک‌های Residual) و دانش‌آموز UNet ساده قرار دارند. در دو ردیف انتهایی، دو مدل دانش‌آموز به صورت تنها و بدون استفاده از چهارچوب چگالش دانش‌، ارزیابی شده‌اند.

\begin{table}[H]
	\caption{معیار Dice برای مدل‌های مختلف}
	\label{distilldice}
	\centering
	\begin{tabular}{lcccc}
		\toprule
		\multicolumn{4}{l}{نام ساختار در ریسک} \\
		
		\cmidrule(r){2-5}
		نام مدل & مری & قلب & نای & آئورت \\
		\midrule
		 UNet آموزگار & $0.73 \pm 0.13$ & $0.95 \pm 0.02$ & $0.93 \pm 0.03$ & $0.86 \pm 0.08$\\
		Resnet دانش‌آموز & $0.45 \pm 0.11$ & $0.62 \pm 0.03$ & $0.81 \pm 0.06$ & $0.63 \pm 0.17$ \\
		Unet دانش‌آموز & $0.62 \pm 0.13 $ & $0.91 \pm 0.04$ & $0.89 \pm 0.07 $ & $0.79 \pm 0.18$ \\
		\midrule
		Resnet تنها & $0.33 \pm 0.07 $ & $0.13 \pm 0.04 $ & $0.80 \pm 0.05$ & $0.22 \pm 0.05$ \\
		 Unet تنها & $0.54 \pm 0.13$ & $0.79 \pm 0.09$ & $0.88 \pm 0.05$ & $0.64 \pm 0.17$ \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\caption{معیار Jaccard برای مدل‌های مختلف}
	\label{distilljaccard}
	\centering
	\begin{tabular}{lcccc}
		\toprule
		\multicolumn{4}{l}{نام ساختار در ریسک} \\
		
		\cmidrule(r){2-5}
		نام مدل & مری & قلب & نای & آئورت \\
		\midrule
		Unet آموزگار & $0.64 \pm 0.12$ & $0.93 \pm 0.03$ & $0.90 \pm 0.03$ & $0.82 \pm 0.09$\\
		Resnet دانش‌آموز & $0.38 \pm 0.09$ & $0.60 \pm 0.03$ & $0.77 \pm 0.07$ & $0.56 \pm 0.16$ \\
		Unet دانش‌آموز & $0.53 \pm 0.11 $ & $0.89 \pm 0.04$ & $0.86 \pm 0.07 $ & $0.74 \pm 0.19$ \\
		\midrule
		Resnet تنها & $0.29 \pm 0.05 $ & $0.09 \pm 0.03 $ & $0.76 \pm 0.05$ & $0.22 \pm 0.04$ \\
		Unet تنها & $0.45 \pm 0.11$ & $0.77 \pm 0.09$ & $0.85 \pm 0.06$ & $0.56 \pm 0.15$ \\
		\bottomrule
	\end{tabular}
\end{table}


یک نمونه از خروجی قطعه‌بندی تصاویر سی‌تی اسکن سه‌بعدی دادگان آزمایش، در چهار نمای مختلف اکسیاب، سجیتال، کرونال و سه‌بعدی برای مدل‌های مختلف در شکل ~\رجوع{شکل:دیستیلپرید} نشان داده شده است که در آن (الف) قطعه‌بندی مطلوب، (ب) پیش‌بینی مدل آموزگار، (پ) پیش‌بینی دانش‌آموز Resnet (ت) پیش‌بینی دانش‌آموز UNet، (ث) پیش‌بینی Resnet تنها و (ج) پیش‌بینی UNet ساده‌ی تنها هستند.

\شروع{شکل}[H]
\centerimg{04distillationoutputs.png}{15cm}
\شرح{خروجی مدل‌های مختلف به صورت آموزش داده‌ شده با چارچوب چگالش دانش و تکی، (الف) قطعه‌بندی مطلوب، (ب) پیش‌بینی مدل آموزگار، (پ) پیش‌بینی دانش‌آموز Resnet (ت) پیش‌بینی دانش‌آموز UNet، (ث) پیش‌بینی Resnet تنها و (ج) پیش‌بینی UNet ساده‌ی تنها}
\برچسب{شکل:دیستیلپرید}
\پایان{شکل}

\زیرزیرقسمت{بحث و نتیجه‌گیری}

همانطور که اشاره گردید، هدف از چارچوب چگالش دانش، انتقال دانش یادگیری شده از آموزگار به دانش‌آموز است که این‌ روند باعث بهبود دقت و یادگیری بهتر در دانش‌آموز می‌شود. همانطور که در جدول‌های ~\رجوع{distilldice} و ~\رجوع{distilljaccard} و شکل ~\رجوع{شکل:دیستیلپرید} ملاحظه‌ گردید، استفاده از این چارچوب باعث افزایش دقت عملکرد در قطعه‌بندی ساختارهای در ریسک بدون تغییر مدل و اضافه کردن هزینه‌ی محاسباتی می‌شود. برای مقایسه‌ی بهتر بهبود عملکرد نمودار جعبه‌ای\LTRfootnote{Box Plot} معیار Dice دادگان آزمایش برای چهار ساختار در ریسک و برای پنج شبکه‌ی آموزش داده شده به صورت یک‌جا در شکل ~\رجوع{شکل:باکسپلاتدایسدیستیل} رسم گردید. همانطور که ملاحظه می‌شود شبکه‌هایی دانش‌آموز که یکبار به صورت تکی و بار دیگر با چارچوب چگالش دانش آموزش دیده‌اند، عملکردشان بهبود یافته است.

\شروع{شکل}[H]
\centerimg{04boxplotdistill.png}{15cm}
\شرح{نمودار جعبه‌ای معیار Dice دادگان آزمایش برای چهار ساختار در ریسک و پنج شبکه‌ی آموزش داده شده}
\برچسب{شکل:باکسپلاتدایسدیستیل}
\پایان{شکل}

برای شهود بیشتر عملکرد چارچوب چگالش دانش، شکل ~\رجوع{شکل:هیتمپدیستیل} را در نظر بگیرید. در این شکل، نقشه‌ی احتمالاتی خروجی شبکه‌ها قبل از آستانه‌گذاری برای قلب نشان داده شده است. ملاحظه می‌شود که طبق انتظار، پس‌زمینه‌ی تصویر با احتمال $0.25$ در این نقشه ظاهر شده است و برای ساختارهای دیگر مانند نای، مری و آئورت، احتمال بسیار نزدیک به صفر است. نکته‌ی قابل توجه در نقشه‌ی احتمالاتی دانش‌آموزان با و بدون استفاده از چگالش دانش است که در در Resnet احتمال بالایی برای حضور قلب در سمت راست بدن ایجاد شده است اما بعد از چگالش دانش این مشکل رفع شده است.

\شروع{شکل}[H]
\centerimg{04heatmapdistill.png}{15cm}
\شرح{نقشه‌های احتمالاتی خروجی شبکه‌ها قبل از آستانه‌گذاری (الف)  آموزگار (ب) دانش‌آموز Resnet (پ) دانش‌آموز UNet (ت) Resnet تنها (ث) UNet تنها}
\برچسب{شکل:هیتمپدیستیل}
\پایان{شکل}

هدف چگالش دانش افزایش دقت در مدل‌های ضعیف‌تر است. برای مقایسه‌ی میزان پیچیدگی مدل‌ها از سه معیار تعداد پارامترهای قابل یادگیری (بر حسب میلیون)، تعداد عملیات اعشاری در واحد زمان\LTRfootnote{Floating Point Operations Per Second (FLOPS)} (بر حسب میلیارد) و متوسط زمان اجرا بر روی تصاویر سه‌بعدی (بر حسب ثانیه) در جدول ~\رجوع{modelscomplexity} نشان داده شده است که حاکی از پیچیدگی بسیار زیاد مدل آموزگار نسبت به مدل‌های دانش‌آموز است. اما با استفاده از روش چگالش دانش، ملاحظه گردید که بدون افزایش پیچیدگی مدل می‌توان دقت آن را به دقت بالاتری رسانید و از هزینه‌های محاسباتی بالا و زمان پردازش زیاد جلوگیری نمود.


\begin{table}[H]
	\caption{مقابسه‌ی میزان پیچیدگی و هزینه‌ی محاسباتی هر مدل}
	\label{modelscomplexity}
	\centering
	\begin{tabular}{lccc}
		\toprule
		نام شبکه & تعداد پارامترها (میلیون) & FLOPs(G) &زمان اجرا (ثانیه) \\
		\midrule
		Unet آموزگار & $33.542$ & $183$ & $14.2$ \\
		Resnet & $0.083$ & $18.1$ & $3.54$ \\
		Unet ساده & $0.540$ & $2.71$ & $2.26$ \\
		
		\bottomrule
	\end{tabular}
\end{table}

%####################################################################################
%####################################################################################
%####################################################################################
\زیرقسمت{بازخورد خطای پیش‌بین برای قطعه‌بندی ساختار‌های در ریسک}

همانطور که می‌دانید، عملکرد شبکه‌های عمیق علی‌الخصوص شبکه‌های کانوولوشنی عمیق بر اساس عملکرد کورتکس بینایی انسان طراحی شده است. از بین مدل‌هایی که برای عملکرد سیستم عصبی ارایه شده است، مدل کدگذاری پیش‌بین\LTRfootnote{Predictive Coding Model}  بر اساس شبکه‌های بازگشتی\LTRfootnote{Recurrent Networks}، یک مسیر بازخورد از لایه‌های بالاتر به لایه‌ها پایین‌تر که حاوی پیش‌بینی عملکرد ناحیه‌های پایینی کورتکس است، متصل می‌شود و در مسیر روبه‌جلو، خطای پیش‌بینی شده جریان می‌یابد \مرجع{rao1999predictive}.  

با الگوبرداری از این مدل، در این قسمت قصد داریم با اضافه کردن یک مسیر پیش‌بین به شبکه‌های روبه‌جلوی کانوولوشنی و بازخورد دادن خطای پیش‌بینی، یک چارچوب برای افزایش دقت شبکه‌های قطعه‌بند برای قطعه‌بندی ساختارهای در ریسک ارایه دهیم.

پیش‌تر اشاره گردید که مفهوم و عملکرد شبکه‌های کانوولوشنی عمیق از عملکرد مغز الگو برداری شده است اما بر خلاف مدل‌ کدگذاری پیش‌بین، فقط یک مسیر رو به جلو در طراحی این شبکه‌ها لحاظ شده است در صورتی که در عملکرد کورتکس بینایی مسیرهای بازگشتی برای بازخورد خطا از لایه‌های بالاتر به لایه‌های پایین‌تر نیز وجود دارد. برای رفع این مشکل، چارچوب بازخورد خطای پیش‌بین در این مطالعه ارایه گردیده است.

\زیرزیرقسمت{معماری چارچوب و آموزش مدل}

چارچوب بازخورد خطای پیش‌بین، از یک شبکه‌ی رمزگذار (Encoder) و دو شبکه‌ی رمزگشا (Decoder) تشکیل شده‌است. برای شهود بیشتر شکل ~\رجوع{شکل:پیپفریمورک} را در نظر بگیرید که در آن قصد، قطعه‌بندی ساختارهای در ریسک لایه‌های دوبعدی تصاویر سه‌بعدی سی‌تی اسکن است. این چارچوب از سه مسیر که در شکل نشان داده شده‌اند، تشکل شده است:

\شروع{فقرات}
\فقره مسیر اول یا مسیر بازسازی ورودی
\فقره مسیر بازخورد خطای پیش‌بین
\فقره مسیر دوم یا مسیر پیش‌بینی قطعه‌بندی
\پایان{فقرات}

\شروع{شکل}[H]
\centerimg{04EFbNet.png}{15cm}
\شرح{عملکرد چارچوب بازخورد خطای پیش‌بین برای قطعه‌بندی ساختارهای در ریسک}
\برچسب{شکل:پیپفریمورک}
\پایان{شکل}

در مسیر اول ابتدا تصویر ورودی به شبکه‌ی کدگذار وارد می‌شود و بردارهای ویژگی استخراج شده از آن، به شبکه رمزگشای اول (قسمت بازسازی) وارد می‌شود تا از تصویر ورودی یک بازسازی حاصل شود. سپس این بازسازی با تصویر اولیه مقایسه‌ می‌شود تا نواحی‌ای که به اشتباه بازسازی شده‌اند مشخص شوند. این اختلاف بازسازی با یک ضریب با تصویر پیش‌بینی شده، جمع می‌شود و از طریق مسیر بازخورد به قسمت شبکه‌ی رمزگذار بازخورد داده می‌شود. تا این قسمت از روند را می‌توان به صورت زیر فرمول‌بندی نمود:

\begin{alignat}{5}
	&X' = Decoder_1(Encoder(X))    \label{recpep} && \\
	&Z = X' + \beta|X'-X| && \notag
\end{alignat}

که در آن $X$ تصویر ورودی، $X'$ تصویر بازسازی شده، $Z$ تصویر شامل‌ خطای پیش‌بینی در مسیر بازخورد و $\beta$ ضریب ثابت برای جمع وزن‌دار تصویر پیش‌بینی با خطای بازسازی است.

در گام بعدی از مسیر دوم، مجموع وزن‌دار خطای پیش‌بینی و تصویر پیش‌بینی شده وارد شبکه‌ی کدگذار و سپس از قسمت کدگشای شبکه‌ی قطعه‌بند عبور می‌کند تا قطعه‌بندی نهایی تولید گردد. عملکرد این قسمت نیز به شکل زیر فرمول‌بندی می‌شود.

\begin{alignat}{5}
	&P = Decoder_2(Encoder(Z))    \label{segpep} &&
\end{alignat}

که در آن $P$ خروجی قطعه‌بندی نهایی است. برای آموزش یک شبکه توسط این چارچوب، لازم است دو تابع هزینه تعریف گردد، تابع هزینه‌ی شبکه بازسازی کننده که باید فاصله‌ی میان تصویر بازسازی شده و تصویر اولیه را کمینه کند و تابع هزینه‌ی شبکه قطعه‌بندی که هزینه‌ی بین ماسک قطعه‌بندی خروجی و قطعه‌بندی مطلوب را کمینه می‌کند. برای تابع هزینه‌ی باز سازی می‌توان از میانگین مربعات خطا\LTRfootnote{Mean Square    Error} (MSE) و برای تابع هزینه‌ی قطعه‌بندی از BCE استفاده کرد. جمع وزن‌دار این دو تابع هزینه، هزینه‌ی نهایی را ایجاد می‌کند. معادلات  ~\رجوع{pepfinalloss} تابع هزینه‌ی این چارچوب را به صورت فرمول‌بندی نشان می‌دهد.

\begin{alignat}{5}
	&MSE(X, X') = \frac{1}{N} \sum_{i=1}^{N}(X_i-X_i')^2    \notag  && \\
	&Loss = \alpha MSE(X, X') + BCE(Y, P) && \label{pepfinalloss}
\end{alignat}

برای ارزیابی این چارچوب از معماری یک UNet مطابق با شکل ~\رجوع{شکل:پیپیونت} استفاده گردید. برای شبکه‌های رمزگذار و رمزگشای معرفی شده در شکل ~\رجوع{شکل:پیپفریمورک}، از قسمت‌های Encoder و  Decoder معماری شبکه‌ی زیر استفاده گردید. که Encoder برای دو شبکه‌ی Decoder به صورت مشترک عمل می‌کند. مسیرهای اتصالی از Encoder به Decoder‌ها همچنان در چارچوب معرفی شده برای استفاده از شبکه‌ی UNet  پا برجا هستند.

\شروع{شکل}[H]
\centerimg{04pepunet.png}{12cm}
\شرح{معماری شبکه‌ی UNet استفاده شده برای آموزش با چارچوب بازخورد خطای پیشبین}
\برچسب{شکل:پیپیونت}
\پایان{شکل}

برای آموزش این شبکه، از مجموعه دادگان SegTHOR با شرایط گفته شده در بخش‌های قبل استفاده گردید. پارامترهای $\alpha$ و $\beta$ در معادلات ~\رجوع{pepfinalloss} و ~\رجوع{recpep} به ترتیب برابر با $0.2$ و $2$ در روند آموزش قرار داده شد.

\زیرزیرقسمت{نتایج و ملاحظات}

شبکه‌ی UNet یک‌ مرتبه به صورت تکی و یک بار با استفاده از چارچوب بازخورد خطای پیش‌بین، آموزش داده شد. معیارهای ارزیابی برای این دو شبکه به صورت زیر بر روی دادگان آزمایش استخراج گردید.


\begin{table}[H]
	\caption{معیارهای ارزیابی قطعه‌بندی برای شبکه‌ی آموزش دیده شده به دو صورت تکی و چارچوب بازخورد خطای پیشبین}
	\label{peptableresults}
	\begin{tabular}{lllllll}
		\hline
		\multirow{2}{*}{نام شبکه}      & \multirow{2}{*}{معیار} & \multicolumn{4}{r}{نام ساختار در ریسک}                & \multirow{2}{*}{میانگین} \\ \cline{3-6}
		&                        & مری   & قلب       & نای     & آئورت       &                          \\ \hline
		\multirow{3}{*}{Unet با چارچوب}          & Dice                    & $0.68 \pm 0.08$  & $0.88\pm0.04$   & $0.88\pm0.03$   & $0.82\pm0.13$   & $0.82\pm0.07$                \\ \cline{2-7} 
		& Hausdorff                   & $4.63\pm0.73$   & $8.37\pm1.06$   & $4.67\pm0.40$   & $6.16\pm1.01$   & $5.96\pm0.80$                \\ \cline{2-7} 
		& Jaccard                  & $0.58\pm0.08$   & $0.87\pm0.04$   & $0.85\pm0.04$   & $0.76\pm0.14$   & $0.77\pm0.07$                \\ \hline
		\multirow{3}{*}{Unet تنها} & Dice                   & $0.54 \pm 0.13$ & $0.79 \pm 0.09$ & $0.88 \pm 0.05$ & $0.64 \pm 0.17$ & $0.71\pm0.11$                \\ \cline{2-7} 
		& Hausdorff                  & $4.70 \pm 0.56$ & $9.50 \pm 1.49$ & $4.52 \pm 0.18$ & $6.63 \pm 0.86$ & $6.34\pm0.77$                \\ \cline{2-7} 
		& Jaccard                  & $0.45 \pm 0.11$ & $0.77 \pm 0.09$ & $0.85 \pm 0.06$ & $0.56 \pm 0.15$ & $0.66\pm0.10$                \\ \hline
	\end{tabular}
\end{table}

شکل ~\رجوع{شکل:پیپاوتس} پیش‌بینی دو شبکه‌ی UNet آموزش دیده شده به صورت تکی (ب) و با چارچوب بازخورد خطای پیش‌بین (پ) را در کنار قطعه‌بندی مطلوب (الف) در نماهای مختلف نشان می‌دهد. 

\شروع{شکل}[H]
\centerimg{04pepoutputs.png}{12cm}
\شرح{پیش‌بینی قطعه‌بندی ساختارهای در ریسک در نماهای مختلف (الف) خروجی مطلوب (ب) خروجی UNet تنها (پ) خروجی UNet آموزش دیده شده با چارچوب بازخورد خطای پیش‌بین}
\برچسب{شکل:پیپاوتس}
\پایان{شکل}

همانطور که در شکل ~\رجوع{شکل:پیپاوتس} و جدول ~\رجوع{peptableresults} ملاحظه‌ می‌شود با استفاده کردن از چارچوب بازخورد خطای پیشبین، دقت قطعه‌بندی برای ساختارهای در ریسک افزایش خواهد یافت (میانگین معیار Dice برای چهار ارگان در ریسک $0.11$ رشد داشته است). علت این بهبود در استفاده از این چارچوب را می‌توان در دو دلیل توضیح داد:

\شروع{فقرات}
\فقره استفاده از یک Encoder مشترک در بازسازی ورودی و قطعه‌بندی آن با توابع هزینه‌ی مختلف، باعث هدایت کردن Encoder به سمت استخراج ویژگی‌های سطح بالا و در نتیجه بهبود عملکرد قسمت‌ قطعه‌بندی می‌شود.

\فقره با جمع کردن خطای پیش‌بینی شده با تصویر بازسازی شده و عبور دادن این تصویر برای قطعه‌بندی، ناحیه‌هایی که شبکه توانایی بازسازی آن‌ها نداشته است مورد تاکید قرار می‌گیرند و در مسیر دوم باعث بهبود دقت قطعه‌بندی خواهند شد.
\پایان{فقرات}

بنابراین در این قسمت یک چارچوب برای آموزش شبکه‌های عصبی عمیق با رویکرد بازخورد خطا برای افزایش دقت قطعه‌بندی ارایه گردید و ملاحظه شد، با آموزش یک UNet با استفاده از این چارچوب دقت به صورت قابل ملاحظه‌ای افزایش یافت.
%####################################################################################
%####################################################################################
%####################################################################################
\زیرقسمت{معرفی تابع هزینه‌ی بر اساس شکل برای قطعه‌بندی ساختارهای در ریسک}

ابزارهای یادگیری عمیق نسبت به ابزارهای کلاسیک دیگر در حوزه‌ی قطعه‌بندی تصاویر پزشکی، دقت بسیار بالاتری نشان داده است. عناصر سازنده‌ی یک الگوریتم یادگیری عمیق از موارد زیر تشکیل شده است \مرجع{fidon2020generalized}.

\شروع{فقرات}
\فقره معماری شبکه با تعداد پارامتر قابل یادگیری مناسب برای تشکیل نگاشت غیرخطی بین ورودی و خروجی
\فقره تایع هزینه‌ی مناسب برای آموزش شبکه
\فقره دادگان آموزش مناسب 
\فقره الگوریتم بهینه‌سازی برای تنظیم وزن‌های شبکه
\پایان{فقرات}

هر گونه ضعف در یکی از موارد بالا باعث ایجاد خروجی نامطلوب در پیش‌بینی شبکه‌ی عصبی عمیق می‌شود. یکی از موارد ضعف این مدل‌ها که در شکل‌های ~\رجوع{شکل:دیستیلپرید} و ~\رجوع{شکل:پیپاوتس} مشاهده می‌شود وجود جزیره‌ای‌ از قطعه‌بندی‌های نامطلوب یا سوراخ‌هایی در یک بافت یکپارچه است. مطالعات اخیر نشان می‌دهد، برخلاف توانمندی بسیار بالای مدل‌های یادگیری عمیق در استخراج ویژگی‌های سطح بالا، این مدل‌ها توانایی یادگیری شکل و ساختار بافت‌ها را ندارند \مرجع{klyuzhin2022testing}. علت این کاستی را در تابع هزینه‌ی طراحی شده برای شبکه‌های عصبی می‌توان یافت. این توابع هزینه معمولا به صورت پیکسل به پیکسل عمل می‌کنند (مانند BCE ) و ویژگی‌های مربوط به شکل و ساختار عضو مورد مطالعه را در نظر نمی‌گیرند.

بنابراین این مشکل در خروجی قطعه‌بندی باعث پدید آمدن کاستی‌هایی مانند، تکه‌تکه شدن ساختارهای یکپارچه، پدید آمدن جزیره‌های واکسلی و ناهمگونی شکل در ساختار قطعه‌بندی شده، می‌شود. روش‌های بسیاری برای حل این مشکل از طریق ایجاد یک دانش اولیه\LTRfootnote{Prior Knowledge} برای قطعه‌بندی و یا روش‌های پس‌پردازش\LTRfootnote{Post-Processing} ارایه شده است که از جمله‌ی آن‌ها می‌توان به فیلد‌های تصادفی شرطی/مارکوف\LTRfootnote{Conditional/Markov Random Fields} و مدل‌های کانتور فعال\LTRfootnote{Active Contour Models} اشاره کرد \مرجع{bohlender2021survey}.

همانطور که گفته شد این روش‌ها با تاثیر بر روی ورودی یا خروجی نهایی شبکه‌ی عصبی سعی در حل مشکلات ذکر شده دارند. اما هنوز مشکل حل نشده باقی مانده است و شبکه ویژگی‌های مربوط به شکل و ساختار را یاد نگرفته است. تا کنون تلاش‌هایی برای اجبار شبکه به یادگیری شکل شده است. محققی و همکاران \مرجع{mohagheghi2020incorporating} در مطالعه‌ای برای قطعه‌بندی سه‌بعدی کبد با شبکه‌های عصبی عمیق، یک چارچوب برای استخراج ویژگی‌های شکل معرفی کرده‌اند. رویکرد آن‌ها استفاده از یک شبکه‌ی دیگر که ماسک قطعه‌بندی را بازسازی می‌کند و ویزگی‌های مربوط به این ماسک قطعه‌بندی شده‌ی سه‌بعدی را استخراج می‌کند سپس در شبکه‌ی قطعه‌بند یک تابع هزینه برای کمینه‌کردن فاصله‌ی ویژگی‌های استخراج شده از قطعه‌بندی مطلوب و قطعه‌بندی پیش‌بینی شده، اضافه نموده است. با وجود بهبود دقت در قطعه‌بندی، در این چارچوب، هنوز اطمینانی وجود ندارد که شبکه‌ی استخراج کننده‌ی ویژگی، ویژگی‌های مربوط به شکل را استخراج کرده است. بنابراین در این مطالعه سعی داریم تایع هزینه‌ای پیشنهاد کنیم که با اطمینان، ویژگی‌ها شکل و ساختار مورد نظر را استخراج و مقایسه کند.

ساختارهای در ریسک موجود در بدن، معمولا شکل و ساختار خاصی دارند و در بین بیماران مختلف تغییرات نسبتا کمی دارند. بنابراین با اجبار شبکه به یادگیری شکل این ساختارها می‌توان قطعه‌بندی با دقت بالاتری برای این ساختارها تولید نمود. 

\زیرزیرقسمت{استخراج ویژگی‌ تمایز پذیر بر اساس شکل}

برای ایجاد ویژگی‌های تمایز پذیر بر اساس شکل و ساختار، لازم است ابتدا فضای شکل\LTRfootnote{Shape-Space} تعریف شود تا بتوان ویژگی‌های مشترک میان اعضای سازنده‌ی آن فضا را استخراج نمود. برای این کار از ایده‌ی معرفی شده در مقاله‌ی Eigenface \مرجع{turk1991face} می‌توان استفاده کرد که با استخراج بردارهای ویژه از فضای برداری شده‌ی تصاویر چهره، امکان بازسازی تصویر اولیه را با مجموع ‌‌دار بردارهای ویژه فراهم می‌سازد. 

شکل ~\رجوع{شکل:ایگنفیس} قسمت (الف) صد نمونه از تصاویر خاکستری چهره، با ابعاد $32\times32$ را نشان می‌دهد. برای استخراج بردارهای ویژه، ابتدا این تصاویر برداری‌سازی\LTRfootnote{Vectorize} شده و به بردار با ابعاد $1024$ تغییر اندازه داده می‌شود. سپس ماتریس کوواریانس از این مجموعه بردارها، که فضای شکل  را می‌سازند، استخراج می‌شود و با اعمال الگوریتم PCA   \LTRfootnote{Principal Component Analysis} بردارهای ویژه (چهره‌های ویژه) و مقادیر ویژه استخراج می‌شود. پس از استخراج چهره‌های ویژه، با تغییر ابعاد مجدد به $32\times32$ می‌توان این تصاویر را در شکل ~\رجوع{شکل:ایگنفیس} قسمت (ب) مشاهده نمود. فرمول‌بندی این روند را می‌توان به صورت زیر بیان نمود:

\begin{alignat}{5}
	&\mathbf{\theta}_i =  \mathbf{L}_i - \mathbf{\mu} \qquad  \mathbf{\mu} = \frac{1}{n}\sum_{i=1}^{n} \mathbf{L}_i \notag && \\
	&C = \frac{1}{n}\sum_{i=1}^{n}\mathbf{\theta}_i\mathbf{\theta}_i^{T} = \frac{1}{n}\Theta\Theta^T \qquad   \Theta = [\theta_1, \theta_2, ..., \theta_n]\notag && \\
	&C\mathbf{u}_i = \frac{1}{n}\Theta\Theta^T\mathbf{u}_i=\lambda_i\mathbf{u}_i \label{eigenvecdecomp} &&
\end{alignat}

که در آن، $\mathbf{L}_i$ تصویر برداری شده‌ی شماره‌ی $i$ ، $\mu$ میانگین تصاویر برداری شده، C ماتریس کوواریانس، $\mathbf{u}_i$ بردار ویژه و $\lambda_i$ مقدار ویژه است.

\شروع{شکل}[H]
\centerimg{04eigenface.png}{15cm}
\شرح{استخراج بردارهای ویژه از تصاویر چهره و مقایسه با تصاویر غیر چهره (الف) صد نمونه از تصاویر چهره‌ی استفاده شده، (ب) صد چهره‌ی ویژه (بردارهای ویژه‌ از دادگان چهره) و (پ) صد نمونه تصویر غیر چهره (دادگان      FashionMNIST ) }
\برچسب{شکل:ایگنفیس}
\پایان{شکل}

با جمع ‌‌دار این چهره‌های ویژه، می‌توان یک تصویر را بازسازی نمود. شکل ~\رجوع{شکل:فیسریکانس} بازسازی یک تصویر چهره (سمت چپ) را با استفاده از چهره‌های ویژه را نشان می‌دهد که با جمع وزن‌دار تمام این چهره‌های ویژه می‌توان دقیقا به تصویر اصلی رسید (وسط) اما با کم کردن چهره‌های ویژه، کلیت چهره قابل تشحیص است اما دقیقا مانند تصویر اصلی نیست (سمت راست). 

وزن‌های بازسازی از فرمول‌های زیر استخراج می‌شود.
\begin{alignat}{5}
	&\mathbf{w} = \mathbf{L}_i \times U   \qquad  U = [\mathbf{u}_1, \mathbf{u}_2,..., \mathbf{u}_n] \label{recweight} && \\
	&\mathbf{L}_i' = U \mathbf{w}^T \label{recimg} && 
\end{alignat}

که $\mathbf{L}_i'$ تصویر برداری بازسازی شده، U ماتریس بردارهای ویژه و w بردار وزن‌های بازسازی است.

\شروع{شکل}[H]
\centerimg{04facereconstruction.png}{10cm}
\شرح{بازسازی یک تصویر چهره با استفاده از چهره‌های ویژه، سمت چپ: تصویر اصلی، وسط: تصویر بازسازی شده با تمام چهره‌های ویژه، سمت راست: تصویر بازسازی شده با 20 چهر‌ه‌ی ویژه‌ی اول  }
\برچسب{شکل:فیسریکانس}
\پایان{شکل}

حال سوالی که پیش می‌آید اینست که آیا می‌توان با استفاده از این چهره‌های ویژه تصاویر دیگر را بازسازی کرد؟ شکل ~\رجوع{شکل:نانفیسریکانس} نشان می‌دهد با استفاده از تمام بردارهای ویژه می‌توان یک تصویر غیرچهره (صندلی) را به طور کامل بازسازی نمود. بنابراین ویژگی‌ای که باعث پدید آمدن تصاویر مختلف در طی بازسازی می‌شود، وزن‌های بازسازی است. در نتیجه می‌توان از این وزن‌ها برای تفکیک تصاویر چهره و غیرچهره استفاده کرد.

\شروع{شکل}[H]
\centerimg{04nonfacerec.png}{10cm}
\شرح{بازسازی یک تصویر غیرچهره با استفاده از چهره‌های ویژه، سمت چپ: تصویر اصلی، سمت راست: تصویر بازسازی شده با تمام چهر‌ه‌ها‌ی ویژه }
\برچسب{شکل:نانفیسریکانس}
\پایان{شکل}

برای بررسی چگونگی تفکیک‌پذیری تصاویر چهره و غیر چهره، 300 تصویر چهره و 300 تصویر غیر چهره (دادگان آموزش) مطابق شکل ~\رجوع{شکل:ایگنفیس}، (الف) و (پ) استفاده گردید. ابتدا با به‌کارگیری چهره‌های ویژه، بردار وزن‌های بازسازی برای هر دو گروه چهره و غیرچهره استخراج گردید و هیستوگرام این وزن‌ها رسم شد. شکل   ~\رجوع{شکل:فیسکورتوسیس} (الف)، هیستوگرام بازسازی وزن‌های دو گروه چهره (رنگ آبی) و غیرچهره (رنگ آجری) را نشان می‌دهد. همانطور که در این شکل مشاهده می‌شود هیستوگرام وزن‌های تصاویر چهره نسبت به غیرچهره، تنک‌تر\LTRfootnote{Sparse} است. دلیل این مشاهده را می‌توان به دلیل همبستگی بالای چهره‌های ویژه و تصاویر چهره دانست که با ضرایب بسیار کمتری می‌توان یک چهره را با این بردارهای ویژه بازسازی کرد، دانست. برعکس در تصاویر غیر چهره همبستگی کمتری میان چهره‌های ویژه و این تصاویر وجود دارد و بنابراین هیستوگرام غیرتنکی بدست می‌آید. با این مشاهده و استدلال، اگر از بردار وزن‌های بازسازی تصویر، ممان چهارم (کورتوسیس\LTRfootnote{Kurtosis}) طبق فرمول زیر، گرفته شود، انتظار می‌رود وزن‌های بازسازی چهره، کورتوسیس بالاتری داشته باشند.

\begin{alignat}{5}
	& Kurt(X) = E \left[\left(\frac{X-\mu}{\sigma}\right)^4\right] \label{kurtosis} && 
\end{alignat}


\شروع{شکل}[H]
\centerimg{04kurtosisrecfacenonface.png}{17cm}
\شرح{تمایز بین تصاویر چهره و غیرچهره بر اساس وزن‌های بازسازی (الف) هیستوگرام وزن‌های بازسازی تصاویر چهره (آبی) و غیرچهره (آجری)، (ب) کورتوسیس وزن‌های بازسازی چهره و غیرچهره برای مجموعه داده‌ی آموزش و استخراج آستانه‌ی طبقه‌بندی با روش اوتسو (پ) طبقه‌بندی کورتوسیس وزن‌های بازسازی برای مجموعه دادگان آزمایش}

\برچسب{شکل:فیسکورتوسیس}
\پایان{شکل}

در شکل ~\رجوع{شکل:فیسکورتوسیس} (ب)، کورتوسیس وزن‌های بازسازی برای 300 داده‌‌ی آموزش چهره و غیرچهره رسم شده است که طبق انتظار، بردارهای وزن‌های بازسازی چهره، کورتوسیس بالاتری دارند. با استفاده از روش آستانه‌گذاری اوتسو، آستانه‌ی بهینه برای طبقه‌بندی این دو گروه از یکدیگر پیدا شد. در نهایت در قسمت (پ) شکل ~\رجوع{شکل:فیسکورتوسیس} برای 4700 تصویر آزمایش، با استفاده از چهره‌های ویژه‌ی استخراج شده در 300 تصویر آموزش، کورتوسیس وزن‌های بازسازی محاسبه گردید و با آستانه‌ی بدست آمده در دادگان آموزش، طبقه‌بندی به دو گروه چهره و غیره‌چهره انجام گردید. دقت این طبقه‌بندی برابر با $99.37$ درصد بدست آمد. 

بنابراین در این بخش توانستیم بر اساس ویژگی شکل و ساختار تصویر یک معیار ارایه دهیم که بین دو گروه تصویر که ساختار ناهمسان دارند تفکیک قایل شود. بنابراین می‌توان از این روند برای تمایز میان شکل‌های معتبر و نامعتبر با توجه به مجموعه دادگان مورد نظر، استفاده نمود.

\زیرزیرقسمت{دادگان و تعریف تابع هزینه‌ی بر اساس شکل}

همانطور که اشاره گردید، اکثر ساختارهای در ریسک، معمولا در میان افراد مختلف شکل و ساختمان یکسانی دارند، حال اگر شبکه مجبور به یادگیری شکل این ساختار شود، قطعه‌بندی آن با دقت بالاتری صورت می‌پذیرد. برای این‌کار از دو مجموعه‌ داده‌ی سی‌تی اسکن قلب و ام‌آرآی هیپوکامپ استفاده گردید. برای تصاویر سی‌تی اسکن قلب از مجموعه داده‌ی SegTHOR استفاده شد و تصویر قلب و قطعه‌بندی متناظر پس از پیش‌پردازش‌های گفته شده در قسمت ~\رجوع{segthor} با بریدن آن در اندازه‌ی $160\times144\times64$ برای 40 تصویر استخراج گردید. از این تصاویر 80 درصد آن به عنوان مجموعه‌ی آموزش و مابقی برای مجموعه‌ی آزمایش به صورت تصادفی انتخاب گردید. 

برای دادگان هیپوکامپ از دادگان و پیش‌پردازش‌های معرفی شده در قسمت ~\رجوع{segthor} استفاده شد و در نهایت 90 درصد (234 مورد) آن به عنوان مجموعه‌ی آموزش و مابقی برای مجموعه‌ی آزمایش (26 مورد) به صورت تصادفی انتخاب گردید. 

حال، با توجه به ویژگی استخراج شده در بخش قبل که بر اساس شکل و ساختار میان تصاویر چهره و غیر چهره تمایز قایل می‌شد، این قابلیت تمایز، برای برچسب‌های پیش‌بینی شده‌ی قطعه‌بندی ساختارها می‌تواند مورد استفاده قرار گیرد. برای این‌کار طبق آنچه‌ گفته شد، ابتدا تصاویر سه‌بعدی برچسب‌ها، برداری می‌شوند و سپس بردار‌های ویژه استخراج می‌گردد. اما در این‌جا یک مشکل وجود دارد. به عنوان مثال، ابعاد برچسب‌های قطعه‌بندی قلب دارای ابعاد $160\times144\times64$ هستند که با برداری کردن این ابعاد به یک بردار با ابعاد $1474560\times1$ تبدیل می‌شود و با قرار دادن آن در فرمول ~\رجوع{eigenvecdecomp} ماتریس کوواریانس C با ابعاد $1474560\times1474560$ بدست می‌آید که عملا در حافظه‌ی رایانه‌های عادی، نمی‌توان آنرا ذخیره کرد. به این ترتیب با تغییر در فرمول‌بندی معادلات ~\رجوع{eigenvecdecomp} می‌توان این مشکل را رفع کرد.

\begin{alignat}{5}
	&\frac{1}{n}\Theta^T\Theta\mathbf{v}_i=\lambda_i\mathbf{v}_i     \notag && \\
	&\left(\frac{1}{n}\Theta^T\Theta\right)\Theta\mathbf{v}_i=\lambda_i(\Theta\mathbf{v}_i) \qquad \mathbf{u}_i = \Theta\mathbf{v}_i \label{modifpca} && 
\end{alignat}

با ایجاد این تغییر به‌جای محاسبه‌ی $\Theta\Theta^T$ که $\Theta$ یک ماتریس $n \times 1474560$ است (n تعداد دادگان سه‌بعدی مجموعه آموزش است)، $\Theta^T\Theta$ محاسبه می‌شود که خروجی آن یک ماتریس $n\times n$ است و قابلیت کنترل‌پذیری بالاتری دارد. در نهایت با استفاده از معادله‌ی ~\رجوع{modifpca} بردارهای ویژه‌ی $\mathbf{u}_i$ موردنظر استخراج می‌گردند.

در نهایت با توصیفات ارایه شده برای برچسب‌های قطعه‌بندی دو مجموعه داده روند توضیح داده شده، اجرا گردید. شکل ~\رجوع{شکل:ایگنارگان} بردارهای ویژه‌ی تغییر اندازه یافته به اندازه‌ی تصاویر اصلی را در سه نمای اکسیال، کرونال و سجیتال برای دو مجموعه داده‌ی قلب (تصویر راست) و هیپوکامپ (سمت چپ) برای ارگان‌های ویژه‌ی\زیرنویس{در این مطالعه، بردارهای ویژه‌ی استخراج شده از ساختارهای بدن را ارگان‌ ویژه می‌نامیم.} اول و دوم و آخر نشان می‌دهد. 

\شروع{شکل}[H]
\centerimg{04eigen_organ.png}{17cm}
\شرح{ارگان‌های ویژه‌ی استخراج شده برای (الف) هیپوکامپ و (ب) قلب در سه نمای اکسیال، کرونال و سجیتال}
\برچسب{شکل:ایگنارگان}
\پایان{شکل}

پس از استخراج ارگان‌های ویژه از تصاویر مجموعه‌ی آموزش، امکان استخراج بردار وزن‌های بازسازی طبق معادله‌ی ~\رجوع{recweight} فراهم می‌شود. برای داده‌های غیر ارگان با همان ابعاد برچسب‌های اصلی، برچسب‌های خراب شده با افزایش\LTRfootnote{َDilation} و کاهش\LTRfootnote{Erosion} و ایجاد سوراخ\LTRfootnote{Holes} در برچسب‌های اصلی و نیز برچسب‌های نویزی، ایجاد گردید. در نهایت وزن‌های بازسازی برای داده‌های ارگان و غیر ارگان، استخراج شد و از این وزن‌ها طبق معادله‌ی ~\رجوع{kurtosis} کورتوسیس گرفته شد.
 
 شکل ~\رجوع{شکل:کورتوسیسارگان}، هیستوگرام وزن‌های بازسازی و هیستوگرام کورتوسیس وزن‌های بازسازی برای دادگان هیپوکامپ و قلب را نشان می‌دهد. همانطور که مشاهده می‌شود، مقدار کورتوسیس برای داده‌ها با شکل‌های حقیقی و صحیح بیشتر است بنابراین با تعریف یک تابع هزینه برای جریمه‌ی شبکه، در ایجاد کورتوسیس وزن‌های بازسازی بالاتر، شکل‌های صحیح ایجاد می‌گردد و در این حالت شبکه قادر به یادگیری ویژگی‌های شکل و ساختار می‌شود. 
 
\شروع{شکل}[H]
\centerimg{04wieghtsAndkurtosis.png}{17cm}
\شرح{(الف) هیستوگرام وزن‌های بازسازی هیپوکامپ و غیر هیپوکامپ، (ب) هیستوگرام کورتوسیس وزن‌های بازسازی هیپوکامپ و غیر هیپوکامپ (تابع هزینه با خط مشکی نشان داده شده است)، (پ) هیستوگرام وزن‌های بازسازی قلب و غیر قلب،  (ت) هیستوگرام کورتوسیس وزن‌های بازسازی قلب و غیر قلب (تابع هزینه با خط مشکی نشان داده شده است). در تصاویر واضح است که مقدار کورتوسیس برای ساختارهای صحیح بالاتر از ساختارهای با شکل ناقص است بنابراین تابع هزینه‌ی تعریف شده، برای جریمه‌ی شبکه به ایجاد ممان چهارم بیشتر برای وزن‌‌های بازسازی است.}
\برچسب{شکل:کورتوسیسارگان}
\پایان{شکل}  

برای تعریف تابع هزینه، با توجه به هیستوگرام کورتوسیس‌ها از یک تابع نمایی کاهنده استفاده گردید که در کورتوسیس‌های بالاتر مقدار کمتر و در کورتوسیس‌های پایین، مقدار بیشتری دارد. بنابراین تابع هزینه‌ی بر اساس شکل\LTRfootnote{Shape-Based Cost Function (SBCF)} را می‌توان با فرمول زیر بیان نمود.

\begin{alignat}{5}
	& SBCF = \beta \exp(-\frac{x-\gamma m}{\delta \sigma}) \label{sbcf} && 
\end{alignat}

که در آن x مقدار کورتوسیس خروجی قطعه‌بندی شبکه، m و $\sigma$ میانگین و انحراف معیار کورتوسیس مجموعه داده‌ی آموزش، $\beta$ ، $\gamma$ و $\delta$ پارامترهای تنظیم برای تابع نمایی کاهنده هستند. برای دو مجموعه داده‌ی قلب و هیپوکامپ، این تابع هزینه با منحنی مشکی در شکل ~\رجوع{شکل:کورتوسیسارگان} نشان داده شده است. در نهایت، تابع هزینه کلی برای آموزش مجموع وزن‌دار تابع هزینه‌ی BCE و SBCF است. که یکی در سطح واکسل‌ها شبکه را جریمه می‌کند و دیگری بر اساس شکل و ساختار تولیدی. معادله‌ی ~\رجوع{sbcfbce} تابع هزینه‌ی نهایی را نشان می‌دهد.

\begin{alignat}{5}
	& TotalLoss = \alpha SBCF(p) + BCE(p, y) \label{sbcfbce} && 
\end{alignat}
   
شکل ~\رجوع{شکل:شیپاورال} توصیف کلی از ساختار تابع هزینه‌ی پیشنهادی برای آموزش یک شبکه را نشان می‌دهد که از برچسب‌های قطعه‌بندی مجموعه‌ی دادگان آموزش، ارگان‌های ویژه استخراج می‌شوند و سپس بر اساس معادلات معرفی شده، کورتوسیس وزن های بازسازی پیش‌بینی شبکه محاسبه می‌شود و به تابع هزینه‌ی بر اساس شکل داده می شود در نهایت مجموع وزن‌دار (با ضریب $\alpha$) تابع هزینه‌ی شکل و BCE وزن‌های شبکه را به‌روزرسانی می‌کند.

\شروع{شکل}[H]
\centerimg{04overallsbcf.png}{10cm}
\شرح{توصیف کلی عملکرد تابع هزینه‌ی پیشنهادی}
\برچسب{شکل:شیپاورال}
\پایان{شکل}  

\زیرزیرقسمت{آموزش شبکه‌ی سه‌بعدی قطعه‌بند برای یادگیری ویژگی‌های شکل}

برای استفاده از تابع هزینه‌ی ارایه شده، لازم است یک شبکه‌ی کانوولوشنی عمیق سه‌بعدی برای پیش‌بینی قطعه‌بندی به صورت حجمی، تعریف گردد. برای این شبکه‌ی سه‌بعدی از معماری پیشنهادی در \مرجع{li2017compactness} استفاده گردید. که معماری آن در شکل ~\رجوع{شکل:سهبعدیکانو} نشان داده شده است.

\شروع{شکل}[H]
\centerimg{04resnetarc.png}{15cm}
\شرح{معماری شبکه‌ی کانوولوشنی سه‌بعدی استفاده شده}
\برچسب{شکل:سهبعدیکانو}
\پایان{شکل}  

در این معماری K تعداد ماتریس‌های ویژگی را نشان می‌دهد که برای آموزش با مجموعه دادگان هیپوکامپ این مقدار برابر با 16 و برای مجموعه دادگان قلب به علت بزرگتر بودن ابعاد تصویر برابر با 3 قرار داده شد (مقدارهای بیشتر باعث سرریز از حافظه و توقف آموزش می‌شد). ضریب $\alpha$ در تابع هزینه‌ی نهایی برای هیپوکامپ $0.1$ و برای قلب 2 در نظر گرفته شد. برای بهینه‌سازی وزن‌های شبکه از الگوریتم بهینه‌سازی Adam استفاده شد و آموزش پس از رسیدن تابع هزینه به حالت ثابت متوقف گردید.

برای ارزیابی عملکرد تابع هزینه‌ی بر اساس شکل، شبکه یک‌ مرتبه با تابع هزینه‌ی پیشنهادی در معادله‌ی ~\رجوع{sbcfbce} آموزش داده شد و بار دیگر تنها از تابع هزینه‌ی BCE استفاده گردید. در ادامه به بررسی نتایج بدست آمده پرداخته می‌شود.

\زیرزیرقسمت{نتایج}
برای ارزیابی عملکرد، همانطور که اشاره گردید، با استفاده از داده‌های سه‌بعدی ام‌آرآی هیپوکامپ و سی‌تی اسکن قلب، شبکه‌ی تمام کانوولوشنی سه‌بعدی با دو تابع هزینه‌ی مختلف آموزش دیده شد. جدول ~\رجوع{sbcftable} معیارهای ارزیابی Dice ، Jaccard و Hausdorff را برای مجموعه دادگان آزمایش نشان می‌دهد. برای مقایسه‌ی آماری بهبود عملکرد تابع هزینه‌ی پیشنهادی با تابع هزینه‌ی BCE از معیار P-value (ردیف سوم در جدول) استفاده گردید که در صورت کمتر بودن این معیار از مقدار $0.05$ رشد چشمگیری در روش‌ ارایه شده نسبت به روش قبلی داشته‌ایم.



\begin{table}[H]
	\caption{معیارهای ارزیابی برای مجموعه دادگان آزمایش برای قطعه‌بندی هیپوکامپ و قلب بر اساس رویکرد تابع هزینه‌ی بر اساس شکل و تابع هزینه‌ی BCE}
	\label{sbcftable}
\begin{tabular}{lllll}
	\hline
	\multirow{2}{*}{نام دادگان}                  & \multirow{2}{*}{روش} & \multicolumn{3}{c}{معیار}                 \\ \cline{3-5} 
	&                         & Dice      & Jaccard   & Hausdorff  \\ \hline
	\multirow{3}{*}{قطعه‌بندی هیپوکامپ} & BCE                 & $0.81\pm0.03$ & $0.69\pm0.05$ & $3.10\pm0.44$          \\ \cline{2-5} 
	& SBCF (روش ما)             & $0.86\pm0.03$ & $0.75\pm0.05$ & $2.58\pm0.35$          \\ \cline{2-5} 
	& P-value                 & $0.000006$  & $0.000003$  & $0.000007$           \\ \hline
	\multirow{3}{*}{قطعه‌بندی قلب}       & BCE                & $0.74\pm0.07$ & $0.59\pm0.08$ & $9.31\pm1.70$          \\ \cline{2-5} 
	& SBCF (روش ما)             & $0.87\pm0.05$ & $0.77\pm0.08$ & $8.60\pm1.39$          \\ \cline{2-5} 
	& P-value                 & $0.0032$    & $0.0026$    & $0.33 $              \\ \hline
\end{tabular}
\end{table}

شکل‌های ~\رجوع{شکل:هیپسگ} و ~\رجوع{شکل:هارتسگ} قطعه‌بندی یک نمونه از تصاویر آزمایش هیپوکامپ و قلب را به ترتیب نشان می‌دهند که با استفاده از دو مدل کانوولوشنی سه‌بعدی آموزش دیده شده با تابع هزینه‌های مختلف، ایجاد شده‌اند. در هر دو تصویر، ردیف اول قطعه‌بندی مطلوب، ردیف دوم، خروجی شبکه‌ی قطعه‌بندی آموزش دیده شده بر اساس تابع هزینه‌ی BCE و ردیف سوم، خروجی شبکه‌ی قطعه‌بندی آموزش دیده شده بر اساس تابع هزینه‌ی پیشنهادی در نماهای اکسیال، کرونال، سجیتال و سه‌بعدی، نشان داده شده است.

با توجه در شکل‌ها خروجی و جدول فوق، علاوه بر افزایش دقت قطعه‌بندی، مشکلاتی از قبیل، تکه‌تکه شدن ساختار، جزیره‌های واکسلی و ناهمگونی شکل با استفاده کردن از تابع هزینه‌ی SBCF از بین رفته است. با دقت در تصویر ~\رجوع{شکل:هیپسگ} و در قسمت‌های بزرگ‌نمایی شده، می‌‌توان دریافت که استفاده از تابع هزینه‌ی BCE باعث بوجود آمدن جزیره‌های واکسلی و تکه‌‌تکه شدن ساختار می‌شود اما با استفاده کردن از تابع هزینه‌ی SBCF این مشکل رفع شده است و شکل و ساختار معتبری برای قطعه‌بندی هیپوکامپ در کنار افزایش دقت قطعه‌بندی، ایجاد گردیده است. به صورت مشابه در شکل ~\رجوع{شکل:هارتسگ} مشکل ناهمگونی شکل (ساختار پیش‌بینی شده برای قلب ساختار معتری نیست) با استفاده از تابع هزینه‌ی پیشنهادی رفع شده است.

\شروع{شکل}[H]
\centerimg{04hippocampuseseg.png}{15cm}
\شرح{قطعه‌بندی تصاویر ام‌آرآی هیپوکامپ، (الف) قطعه‌بندی مطلوب (ب) خروجی قطعه‌بندی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی BCE و (پ) خروجی قطعه‌بندی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی SBCF در نماهای مختلف}
\برچسب{شکل:هیپسگ}
\پایان{شکل}  

\شروع{شکل}[H]
\centerimg{04heartseg.png}{15cm}
\شرح{قطعه‌بندی تصاویر سی‌تی اسکن قلب، (الف) قطعه‌بندی مطلوب (ب) خروجی قطعه‌بندی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی BCE و (پ) خروجی قطعه‌بندی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی SBCF در نماهای مختلف}
\برچسب{شکل:هارتسگ}
\پایان{شکل}  

در شکل ~\رجوع{شکل:شیپبیسباکس} نمودار جعبه‌ای معیار‌های ارزیابی  Dice ، Jaccard و Hausdorff برای دو تابع هزینه‌ی استفاده شده در قطعه‌بندی هیپوکامپ (قسما الف) و قطعه‌بندی قلب (قسمت ب) نشان داده شده است. برای نمایش بهتر، فاصله‌ی Hausdorff در نمودارهای جعبه‌ای به بیشینه‌ی خود تقسیم شد ($4.24$ برای هیپوکامپ و $11.66$ برای قلب).

\شروع{شکل}[H]
\centerimg{04boxplotsbcf.png}{17cm}
\شرح{نمودار جعبه‌ای معیارهای ارزیابی Dice ، Jaccard و Hausdorff برای (الف) قطعه‌بندی هیپوکامپ (ب) قطعه‌بندی قلب}
\برچسب{شکل:شیپبیسباکس}
\پایان{شکل} 

همانطور که در جدول ~\رجوع{sbcftable} و شکل ~\رجوع{شکل:شیپبیسباکس}، مشاهده شد، استفاده از تابع هزینه‌ی بر اساس شکل دقت قطعه‌بندی را افزایش می‌دهد. در نمودارهای جعبه‌ای، یک داده‌ی پرت مشاهده می‌شود که بر اساس تابع هزینه‌ی پیشنهادی بوجود آمده است. این مورد در تصویر ~\رجوع{شکل:پرتهیپوکمپ} نشان داده شده است. در قسمت (الف) پیش‌بینی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی BCE (با رنگ قرمز) در کنار قطعه‌بندی مطلوب (رنگ سبز)، و در قسمت (ب) پیش‌بینی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی SBCF (با رنگ قرمز) در کنار قطعه‌بندی مطلوب (رنگ سبز) نشان داده شده است. مقدار Dice برای این مورد در تصویر (الف) برابر با $0.77$ و در تصویر (ب) برابر با $0.73$ است که فاصله‌ی نسبتا کمی است. اما علی‌رغم بالاتر بودن این معیار، جزیره‌های واکسلی ناخواسته در قطعه‌بندی نهایی BCE وجود دارد (در تصویر (الف) بزرگنمایی شده است)، که این مشکل در تصویر (ب) مشاهده نمی‌شود.

\شروع{شکل}[H]
\centerimg{04outliersbcf.png}{17cm}
\شرح{داده‌ی پرت در قطعه‌بندی هیپوکامپ با استفاده از تابع هزینه‌ی بر اساس شکل، (الف) پیش‌بینی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی BCE (با رنگ قرمز) در کنار قطعه‌بندی مطلوب (رنگ سبز)، (ب) پیش‌بینی شبکه‌ی آموزش دیده شده با تابع هزینه‌ی SBCF (با رنگ قرمز) در کنار قطعه‌بندی مطلوب (رنگ سبز) }
\برچسب{شکل:پرتهیپوکمپ}
\پایان{شکل} 

شکل ~\رجوع{شکل:تستکورتوسیس} هیستوگرام کورتوسیس دادگان آزمایش در قطعه‌بندی‌های پیش‌بینی شده توسط شبکه‌های آموزش دیده شده با دو تابع هزینه ی مختلف برای (الف) هیپوکامپ و (ب) قلب، در کنار هیستوگرام کورتوسیس‌های مطلوب (رنگ آبی) نشان داده شده است. با توجه به تابع هزینه‌ی تعریف شده برای هر مجموعه داده (منحنی‌های مشکی رنگ)، شبکه‌ی آموزش دیده شده با تابع هزینه‌ی SBCF سعی در بیشینه کردن کورتوسیس‌ها و ایجاد شکل و ساختار معتر برای قطعه‌بندی مورد نظر داشته است.


\شروع{شکل}[H]
\centerimg{04predictedkurtosis.png}{17cm}
\شرح{هیستوگرام کورتوسیس پیش‌بینی شده توسط تابع هزینه‌ی BCE (رنگ سبز) و تابع هزینه‌ی SBCF (رنگ آجری) برای داده‌های آزمایش در کنار کورتوسیس‌های مطلوب (رنگ سبز). (الف) دادگان هیپوکامپ (ب) دادگان قلب}
\برچسب{شکل:تستکورتوسیس}
\پایان{شکل} 

\زیرزیرقسمت{جمع‌بندی و نتیجه‌گیری}
در این مطالعه دیدیم شبکه‌های عمیق، نقطه‌ی ضعفی در استخراج ویژگی‌های شکل و یادگیری ساختار دارند. تلاش‌هایی در این زمینه با ایجاد دانش اولیه برای شبکه و نیز پس‌پردازش‌ها برای پالایش خروجی و ایجاد ساختار معتبر شده بود اما هنوز مشکل یادگیری ساختار در این شبکه‌ها وجود داشت. 

برای حل این مشکل، در این پژوهش از رویکرد ایجاد فضای شکل و استخراج ارگان‌های ویژه برای سنجش میزان معتبر بودن ساختار پیش‌بینی شده توسط شبکه، استفاده گردید. روش‌ پیشنهادی استخراج وزن‌های بازسازی ماسک قطعه‌بندی، با توجه به ارگان‌های ویژه‌ است. سپس با محاسبه‌ی کورتوسیس این وزن‌ها ملاحظه گردید ساختارهایی که شکل معتبرتری دارند کورتوسیس بالاتری ایجاد می‌شود. بر همین مبنا تابع هزینه‌ی بر اساس شکل پیشنهاد گردید.

در نهایت با آموزش یک شبکه با و بدون استفاده از این تابع هزینه بر روی دو مجموعه داده‌ی قطعه‌بندی ساختارهای سه‌بعدی در تصاویر سی‌تی اسکن و ام‌آرآی، ملاحظه گردید که نقص‌های شبکه در پیش‌بینی ساختار ناهمگون و ایجاد جزیره‌های واکسلی، برطرف گردید.

از این تابع هزینه، در مواردی که تغییرات ساختار مورد نظر کم باشد می‌توان استفاده کرد و نتایج قطعه‌بندی را بهبود بخشید اما برای قطعه‌بندی ساختارهایی که شکل و موقعیت گوناگونی در تصاویر مختلف دارند (مانند تومور) استفاده از این رویکرد توصیه نمی‌شود.
%####################################################################################
%####################################################################################
%####################################################################################
\قسمت{روش‌ پیشنهادی قطعه‌بندی تومور}

قطعه‌بندی تومور در کنار قطعه‌بندی ساختارهای در ریسک، یک نیاز حیاتی است که لازم است با دقت و سرعت بالایی انجام شود تا در روند تشخیص و درمان مورد استفاده قرار گیرد. قطعه‌بندی تومور نیز یک روند زمان‌بر و خسته‌کننده برای شخص متخصص است (به‌خصوص آنکه این قطعه‌بندی در طی درمان باید چندین مرتبه تکرار گردد). بنابراین خودکار کردن این روند در کلینیک‌های درمانی ضروری است. 

قطعه‌بندی تومور به علت تغییرات اندازه، موقعیت و شکل آن، بسیار چالش‌ برانگیزتر از قطعه‌بندی سایر ساختارهای بدن است که شکل و موقعیت خاصی دارند. بر همین اساس این قطعه‌بندی برای روش‌های خودکار نسبت به روش‌های دستی و نیمه-خودکار بسیار پر چالش‌تر است. روش‌های یادگیری عمیق نسبت به سایر روش‌های  خودکار در قطعه‌بندی تومور دقت بالاتری نشان‌ داده‌اند بنابراین  ذز ادامه قصد داریم روشی مبتنی بر روش‌های یادگیری عمیق برای قطعه‌بندی خودکار تومور ارایه دهیم.

\زیرقسمت{معرفی دادگان و پیش‌ پردازش}

قطعه‌بندی تومور مغزی یک مرحله‌ی مهم، برای تشخیص و درمان سرطان مغزی است. تصاویر ام‌آرآی به علت ایجاد تضاد بالا در بافت‌های نرم و رزولوشن‌ بالایی که برای تصویربرداری تامین می‌کنند، در تحلیل و بررسی ساختارهای مغزی، مطالعه‌ی تومور مغزی و نظارت و تهیه‌ی نقشه‌ی درمان، کاربرد فراوانی دارند. ام‌آرآی برخلاف روش تصویربرداری سی‌تی اسکن از پرتوهای یونیزه شده استفاده نمی‌کند و از این جهت خطرهای پرتوهای پر انرژی را ندارد. 

در کاربردهای کلینیکی، برای تشخیص بهتر، تصویر‌های ام‌آرآی مکمل سه‌بعدی دیگری از جمله، \lr{T1 contrastenhanced (T1ce)} ،\lr{T2-weighted} ،\lr{T1-weighted} و \lr{Fluid Attenuation Inversion Recover (FlAIR)} برای بهبود تضاد، بین بافت‌های نرم و همچنین تومور و پس زمینه، تهیه می‌شوند \مرجع{myronenko20183d}.

مجموعه دادگان BraTS \LTRfootnote{Brain Tumor Segmentation Dataset} شامل چهار دنباله تصویر ام‌آرآی T1 ، T2 ، T1ce و FlAIR برای هر بیمار است که قطعه‌بندی مطلوب متناظر برای هر بیمار توسط متخصص قطعه‌بندی شده است. در هر قطعه‌بندی سه ناحیه برای تومور مشخص شده است که عبارتند از: هسته‌ی تومور\LTRfootnote{Tumor Core}، ناحیه‌ی پیش‌ توموری\LTRfootnote{Peritumoral Edema} و تومور در حال رشد\LTRfootnote{Enhancing Tumor}. این مجموعه دادگان از 369 مورد تشکیل شده ازت که ابعاد تصویر ام‌آرآی در هر مورد $240\times240\times155$ است و فاصله واکسلی برابر با $1\times1\times1$ میلی‌متر مکعب است \مرجع{menze2014multimodal, bakas2017segmentation}. شکل ~\رجوع{شکل:برتسسمپل} چهار دنباله‌ی تصویر و قطعه‌بندی متناظر برای نواحی مختلف تومور را نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{04bratsexp.png}{7cm}
\شرح{چهار دنباله تصویر ام‌آرآی T1 ، T2 ، T1ce و FlAIR برای یک بیمار خاص با قطعه‌بندی متناظر برای تومور (قرمز: هسته ی تومور، زرد: ناحیه‌ی پیش‌ توموری و سبز: تومور در حال رشد)}
\برچسب{شکل:برتسسمپل}
\پایان{شکل}

در این مطالعه، هرچند استفاده از چهار دنباله‌ی تصویر، دقت قطعه‌بندی را افزایش می‌دهد اما تنها از یک دنباله‌ی تصویر FlAIR استفاده گردید. دلیل این‌کار به این علت است که در مراکز درمانی معمولا یک دنباله‌ی تصویر در دسترس است و طبق مطالعات انجام شده دنباله‌ی FlAIR نسبت به سایر دنباله‌ها، تضاد بهتری بین تومور و بافت اطراف فراهم می‌کند \مرجع{bergamino2019comparison}. برای پیش‌پردازش این مجموعه تصاویر ابتدا کناره‌های تصویر به مرکزیت آن بریده شد و ابعاد به $144\times176\times155$ تغییر کرد. سپس مقدار شدت‌ها به مقدار 90 درصد هیستوگرام تجمعی برای نرمال‌سازی صورت گرفت. برای قطعه‌بندی تومور سه برچسب با یکدیگر ترکیب گردید تا قطعه‌بندی تمام تومور انجام گیرد. در نهایت ده درصد از دادگان به عنوان مجموعه‌ی آزمایش و مابقی برای آموزش شبکه‌ استفاده گردید.

\زیرقسمت{معرفی شبکه‌ی بر اساس ساز و کار توجه برای قطعه‌بندی تومور}

چالش اصلی قطعه‌بندی تومور در تصاویر سه‌بعدی پزشکی، تغییرات اندازه و موقعیت تومور و در برخی موارد تضاد پایین میان تومور و بافت‌های کناری است، که این قطعه‌بندی را دشوار می‌کند. روش پیشنهادی ما برای حل این مشکل استفاده از ساز و کار توجه\LTRfootnote{Attention Mechanism} است که باعث می‌شود شبکه، به ناحیه‌هایی که در آن‌ها احتمال حضور تومور وجود دارد، توجه بیشتر کند. برای این منظور، دو ماژول توجه\LTRfootnote{Attention Module} و قطعه‌بندی\LTRfootnote{Segmentation Module} در این مطالعه‌ ارایه گردید که هدف ماژول توجه یافتن موقعیت و ناحیه‌ای است که در آن تومور حضور دارد و سپس ماژول قطعه‌بند با استفاده از اطلاعات ماژول توجه، قطعه‌بندی تومور را به صورت دقیق انجام می‌دهد. 

روش پیشنهادی ما، بر اساس معماری شبکه‌ی UNet دوبعدی، برای ماژول توجه و قطعه‌بند، پایه‌گذاری شده است. ایده‌ی اصلی این مطالعه در شکل ~\رجوع{شکل:اتنشناورال} نشان داده شده است. این ساختار به صورت سریال عمل می‌کند. در ابتدا ماژول توجه یک قطعه‌بندی تقریبی با نرخ مثبت صحیح\LTRfootnote{True Positive Rate} بالا ایجاد می‌کند که برای آموزش این ماژول از ماسک‌های قطعه‌بندی افزایش\LTRfootnote{Dilated}  یافته استفاده می‌شود که وظیفه‌ی آن یافتن موقعیت تومور با یک تابع هزینه‌ی مناسب است. در گام بعدی ویژگی‌های استخراج شده توسط ماژول توجه، در کنار تصویر اصلی به ماژول قطعه‌بند داده می‌شود و قطعه‌بندی نهایی ایجاد می‌گردد که برای آموزش این ماژول از ماسک‌های قطعه‌بندی اصلی (بدون افزایش) استفاده می‌شود.

\شروع{شکل}[H]
\centerimg{04overallattention.png}{10cm}
\شرح{کلیت روش پیشنهادی برای قطعه‌بندی تومور بر اساس ساز و کار ماژول توجه و قطعه‌بند}
\برچسب{شکل:اتنشناورال}
\پایان{شکل}

\زیرزیرقسمت{ماژول توجه}

همانطور که اشاره گردید شبکه‌ی پایه‌ی مورد استفاده، هم برای ماژول توجه و هم برای ماژول قطعه‌بندی، شبکه‌ی UNet می‌باشد که با جزییات روند آموزش در شکل ~\رجوع{شکل:اتنشنارک} نشان داده شده است. هدف ماژول توجه ارایه‌ی یک قطعه‌بندی به صورت تقریبی و یافتن موقعیت تومور است که نرخ مثبت صحیح بالایی داشته باشد و کل تومور را در بر بگیرد. برای این منظور ماسک‌های قطعه‌بندی افزایش یافته به عنوان قطعه‌بندی مطلوب در روند آموزش این ماژول استفاده گردید. علاوه بر این برای اطمینان از بالا بودن نرخ مثبت صحیح، یک تابع هزینه‌ی جدید معرفی گردید که هدف آن بالا بردن این نرخ باشد. 

\شروع{شکل}[H]
\centerimg{04attentionnetArchitecture.png}{17cm}
\شرح{چارچوب پیشنهادی ماژول‌های توجه (قسمت نارنجی) و قطعه‌بند (قسمت سبز) برای قطعه‌بندی تومور به صورت دوبعدی. از معماری UNet به عنوان شبکه‌ی پایه استفاده گردید.}
\برچسب{شکل:اتنشنارک}
\پایان{شکل}

معادله‌ی این تابع هزینه را می‌توان به صورت زیر نوشت که در آن TP ، مثبت صحیح، FN ، منفی غلط، TN ، منفی صحیح و FP ، مثبت غلط است. 

\begin{alignat}{5}
	&SensitivityLoss = 1-\frac{TP}{TP+FN}  \notag && \\
	&SpecificityLoss = 1-\frac{TN}{TN+FP} \notag && \\
	&AttentionLoss = SensitivityLoss + \alpha \times SpecificityLoss \label{attloss} && 
\end{alignat}

وظیفه‌ی این تابع هزینه بیشینه کردن مقدار TP است که با توجه به معادلات این کار در بخش $SensitivityLoss$ انجام می‌شود اما اگر این قسمت به تنهایی استفاده شود خروجی نهایی یک تصویر تمام یک است. برای حل این مشکل و مصالحه میان مثبت صحیح (TP) و منفی صحیح (TN) یک قسمت دیگر ($SpecificityLoss$ ) اضافه گردید تا این مصالحه صورت پذیرد. در نهایت جمع وزن‌دار (با ضریب $\alpha$) این دو قسمت تابع هزینه‌ی نهایی برای ماژول توجه را تشکیل می‌دهد.

\زیرزیرقسمت{ماژول قطعه‌بند}

قسمت سبز رنگ در شکل ~\رجوع{شکل:اتنشنارک}، ماژول قطعه‌بند را نشان می‌دهد. در این قسمت برای آموزش از قطعه‌بندی‌های مطلوب بدون انجام هیچ پردازش (بدون افزایش)، استفاده گردید. برای تابع هزینه‌ی این قسمت از تابع BCE میان پیش‌بینی شبکه و خروجی مطلوب استفاده گردید. 

به قسمت ورودی این ماژول سه تصویر دوبعدی داده می‌شوند که عبارتند از: الف) تصویر دوبعدی ام‌آرآی، ب) خروجی ماژول توجه و پ) ضرب دو مورد قبل در یکدیگر. این سه تصویر در کنار هم قرار می‌گیرند و به ورودی شبکه داده می‌شوند. علاوه بر این ورودی‌ها ویژگی‌های استخراج شده از قسمت Decoder ماژول توجه در کنار ویژگی‌های ماژول قطعه‌بند قرار داده می‌شوند و با اعمال کانوولوشن در Decoder ماژول قطعه‌بند، خروجی قطعه‌بندی نهایی ایجاد می‌گردد. این روند قسمت قطعه‌بند را مجبور به توجه بیشتر به نواحی دارای بافت تومور می کند.

\زیرزیرقسمت{جزییات پیاده‌سازی}

با توجه به شکل ~\رجوع{شکل:اتنشنارک} دو شبکه‌ی مورد استفاده از معماری UNet تبعیت می‌کنند و دارای دو بخش Decoder و Encoder با لایه‌های کانوولوشنی، ادغام و دیکانوولوشن هستند. برای آموزش شبکه‌ها از مجموعه دادگان قطعه‌بندی تومور مغزی در تصاویر ام‌آرآی (BraTS) به صورت دوبعدی با پیش‌پردازش‌های توضیح داده شده در ابعاد $144\times176$ استفاده گردید.

برای آموزش ماژول توجه، ماسک‌های قطعه‌بندی آموزش، با ضریب 21 افزایش داده‌ شد. از تابع هزینه‌ی ~\رجوع{attloss} با قرار دادن ضریب $\alpha$ برابر با $0.5$ برای تاکید بیشتر در ایجاد نرخ مثبت صحیح، در روند آموزش استفاده گردید. در نهایت این مدل آموزش دیده شد و به عنوان یک مدل از پیش آموزش داده شده در روند آموزش ماژول قطعه‌بندی استفاده شد. 

در طی آموزش ماژول قطعه‌بند، خروجی و ویژگی‌های تولید شده در ماژول توجه برای هر مورد استخراج گردید و به ماژول قطعه‌بند طبق شکل ~\رجوع{شکل:اتنشنارک} داده شد. تابع هزینه‌ی این ماژول از BCE میان خروجی مطلوب و پیش‌بینی شبکه ایجاد گردید. برای بهینه‌سازی وزن‌ها از الگوریتم بهینه‌سازی Adam استفاده گردید. برای مقایسه‌ی نتایج، UNet استفاده شده در قسمت ماژول قطعه‌بندی، یکبار بدون استفاده از ماژول توجه و یکبار بااستفاده از این ماژول آموزش داده شد. در ادامه به بررسی نتایج پرداخته می‌شود.

\زیرزیرقسمت{نتایج}

برای ارزیابی عملکرد ماژول توجه، همانطور که اشاره شد، هدف بیشینه کردن نرخ صحیح مثبت است که طبق معادله‌ی زیر این معیار محاسبه می‌شود.

\begin{alignat}{5}
	&TPR = \frac{TP}{TP+FN} \label{tpr} && 
\end{alignat}

این معیار ارزیابی برای مجموعه دادگان آزمایش برابر با $0.998 \pm   0.003$ بدست آمد که نشان می‌دهد موقعیت تومور به طور صحیح و تقریبا کامل پیدا شده است. شکل ~\رجوع{شکل:اتنشناوتس} قسمت (ب) خروجی ماژول توجه را نشان می‌دهد که در مقایسه با قطعه‌بندی مطلوب (قسمت (الف))، تومور را به صورت نادقیق اما با نرخ مثبت صحیح بالا قطعه‌بندی نموده است.

\شروع{شکل}[H]
\centerimg{04attentionouts.png}{16cm}
\شرح{قطعه‌بندی تومور در نماهای مختلف برای یک مورد از دادگان آزمایش، (الف) قطعه‌بندی مطلوب، (ب) خروجی ماژول توجه، (پ) خروجی ماژول قطعه‌بند بر اساس ساز و کار توجه و (ت) خروجی UNet بدون استفاده از ماژول توجه}
\برچسب{شکل:اتنشناوتس}
\پایان{شکل}

برای ارزیابی عملکرد ماژول قطعه‌بند از معیارهای Dice ، Jaccard و Hausdorff استفاده گردید. این معیارها برای دو شبکه‌ی Unet آموزش دیده شده به صورت تکی و با استفاده از ماژول توجه، استخراج گردید. با توجه به جدول ~\رجوع{attable} میانگین معیار Dice با استفاده کردن از مازول توجه از $0.68$ به $0.79$ افزایش یافته است و انحراف معیار آن از $0.18$ به $0.12$ کاهش یافت. برای مقایسه‌ی معنادار بودن این بهبود از معیار P-value استفاده گردید که در سطر آخر جدول نشان داده شده است. کمتر بودن این مقدار از $0.05$ نشانگر پیشرفت چشمگیر است که نشان می‌دهد استفاده از ماژول توجه باعث افزایش دقت قطعه‌بندی می‌شود. شکل ~\رجوع{شکل:باکساتنشن} نمودارهای جعبه‌ای معیارهای ارزیابی را برای دو شبکه نشان می‌دهد. واضح است میانگین و انحراف معیارهای این معیارها با به کارگیری ماژول توجه بهبود می‌یابد.

\begin{table}[H]
	\caption{معیارهای ارزیابی برای مجموعه دادگان آزمایش برای قطعه‌بندی تومور در دو شبکه‌ی Unet بر اساس ماژول توجه و Unet تنها}
	\label{attable}
	\begin{tabular}{llll}
		\hline
		\multirow{2}{*}{نام شبکه} & \multicolumn{3}{c}{نام معیار}                     \\ \cline{2-4} 
		& Dice  & Jaccard  & Hausdorff    \\ \hline
		Unet تنها     & $0.68 \pm 0.18$ & $0.57 \pm 0.17$   & $6.6 \pm 1.0 $           \\ \hline
		Unet با ماژول توجه      & $0.79 \pm 0.12$ & $0.69 \pm 0.15$   & $6.2 \pm 1.0$            \\ \hline
		P-value                      & $0.03 $       & $0.02 $         & $0.06$                 \\ \hline
	\end{tabular}
\end{table}


\شروع{شکل}[H]
\centerimg{04attentionboxplot.png}{16cm}
\شرح{نمودار جعبه‌ای معیارهای ارزیابی Dice ، Jaccard و Hausdorff برای مجموعه دادگان آزمایش در دو شبکه Unet بر اساس ماژول توجه (Unet WA) و Unet تنها}
\برچسب{شکل:باکساتنشن}
\پایان{شکل}

\زیرزیرقسمت{نتیجه‌گیری}

در این مطالعه، یک ماژول توجه برای قطعه‌بندی تومور مغزی ارایه گردید. در این ماژول یک تابع هزینه‌ی جدید برای بیشینه کردن نرخ صحیح مثبت پیشنهاد شد و برای آموزش آن از قطعه‌بندی‌های افزایش (Dilated) داده شده استفاده گردید. این ماژول، در واقع، یک قطعه‌بندی نادقیق اما در برگیرنده‌ی تمام تومور پیش‌بینی می‌کند و می‌تواند موقعیت تومور را با دقت بسیار بالایی استخراج نماید. 

در نهایت برای ارزیابی این ماژول توجه، یک UNet یک مرتبه با به‌کار گیری این ماژول و بار دیگر به صورت تکی بر روی دادگان یکسان، آموزش دیده شد و با استخراج معیارهای ارزیابی، ملاحظه گردید، با به‌کارگیری این ماژول دقت چشمگیری در قطعه‌بندی نهایی خواهیم داشت.

\قسمت{جمع‌بندی}

در این فصل، به معرفی روش‌های پیشنهادی و نتایج بدست آمده پرداخته شد. در ابتدا سه روش برای قطعه‌بندی ساختارهای در ریسک معرفی و ارزیابی شد که در روش اول هدف انتقال دانش از یک مدل پیچیده‌تر به یک مدل ساده‌تر بود که در عین ثابت نگه داشتن پیچیدگی مدل ساده‌تر، دقت آن‌را افزایش می‌دهد. در روش دوم، یک چارچوب بر اساس بازخورد خطای پیش‌بین معرفی گردید که با بازسازی ورودی در یک قسمت، پیش‌بینی قطعه‌بندی در قسمت دیگر و بازخورد دادن خطای بازسازی به ورودی مسیر قطعه‌بندی، قطعه‌بندی ساختارهای در ریسک انجام می‌شد. در روش سوم، یک تابع هزینه‌ی بر اساس شکل پیشنهاد گردید که هدف آن استفاده از ویژگی‌های ساختاری اعضای بدن برای قطعه‌بندی است. با استفاده کردن از این تابع هزینه، مشکلات مربوط به عدم یادگیری شکل در شبکه‌های یادگیری عمیق پاسخ داده شد.

در قسمت نهایی به معرفی یک روش برای قطعه‌بندی پرچالش تومور در تصاویر ام‌آرآی مغزی پرداخته شد. قطعه‌بندی تومور به علت داشتن اندازه، شکل و موقعیت متغیر، نسبت به قطعه‌بندی ساختارهای در ریسک، روندی چالش برانگیزتر است. رویکرد پیشنهادی برای غلبه بر این چالش‌ها، استفاده از ساز و کار توجه برای یافتن موقعیت تومور در یک ماژول توجه بود و در نهایت با راهنمایی‌های ماژول توجه، ماژول قطعه‌بند، قطعه‌بندی دقیق نهایی را انجام می‌داد. 


