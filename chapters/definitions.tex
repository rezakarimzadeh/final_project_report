
\فصل{مفاهیم اولیه}

در این فصل به معرفی حوزه‌ها و مفاهیم اولیه‌ی مرتبط با این پژوهش پرداخته می‌شود. در ابتدا، انواع تصویربرداری پزشکی معرفی و بررسی خواهد شد و در ادامه به تعریف حوزه‌های مرتبط با پردازش تصاویر پزشکی و بینایی کامپیوتر پرداخته می‌شود.

%----------------------------- مقدمه ----------------------------------


\قسمت{تصویربرداری پزشکی}
زمینه‌ی تصویربرداری پزشکی و سیستم‌های تصویرگر، یک زمینه‌ی بسیار گسترده و به نوبه‌ی خود پیچیده است که با استفاده از انواع پرتوهای ایکس، فراصوت، گاما، امواج الکترومغناطیس و ... با تاباندن به بدن بیمار و بازسازی تصویر از روی پرتوهای دریافتی، صورت می‌‌گیرد\زیرنویس{البته در تصویربرداری هسته‌ای، برعکس سایر روش‌های تصویربرداری، منبع تابش پرتو درون بدن بیمار قرار می‌گیرد و با آشکارسازی پرتوهای دریافتی تصویر نهایی تشکیل می‌گردد.}. تصویربرداری پزشکی کمک بسیار زیادی به متخصصین حوزه‌ی سلامت در روند تشخیص و درمان صورت داده است، به طور کلی می‌توان روش‌های تصویر برداری پزشکی را به صورت زیر خلاصه کرد\مرجع{elangovan2016medical}:
\شروع{فقرات}
\فقره رادیوگرافی\LTRfootnote{Radiography}: که شامل تصویربردای‌های بر مبنای پرتوی ایکس است که از مهمترین آن‌ها می‌توان به فلوروسکوپی\LTRfootnote{Fluoroscopy} و رادیوگرافی‌های پروجکشنال\LTRfootnote{Projectional radiographs} اشاره کرد.

\فقره تصویربرداری هسته‌ای\LTRfootnote{Nuclear Imaging}: که با تزریق ایزوتوپ‌های خاص و ذره‌های پرانرژی گسیل شده از مواد رادیواکتیو به بدن بیمار و آشکارسازی پرتوهای دریافتی، تصویر نهایی ساخته می‌شود. از جمله روش‌های تصویربرداری در این حوزه میتوان به PET\LTRfootnote{Positron emission tomography }  و SPECT\LTRfootnote{single-photon emission computerized tomography}  اشاره کرد.

\فقره تصویربرداری فراصوت\LTRfootnote{Ultrasound}: در این نوع از تصویربرداری از کریستال‌های پیزوالکتریک\LTRfootnote{Piezoelectric} برای تولید صوت با فرکانس بالا استفاده می‌شود این صوت به بافت بدن تابانده می‌شود و بازسازی تصویر از روی صوت بازگشتی صورت می‌گیرد. 

\فقره تصویربرداری توموگرافی\LTRfootnote{Tomography}: در تصویربرداری توموگرافی هدف ساخت یک تصویر سه‌بعدی است برای این منظور از لایه‌های مختلف یک شئ بدون آن که بریده شود تصویربرداری صورت می‌گیرد و این لایه‌ها برروی یکدیگر انباشت می‌شوند و در نهایت تصویر سه‌بعدی نهایی ساخته می‌شود. از جمله روش‌های موجود در این حوزه می‌توان به تصویربرداری سی‌تی اسکن و تصویربرداری بر مبنای تشدید مغناطیسی (ام‌آرآی)\LTRfootnote{Magnetic Resonance Imaging (MRI)} اشاره نمود.

\فقره انواع دیگر تصویربرداری مانند: تصویربرداری فوتوآکوستیک\LTRfootnote{Photoacoustic imaging}، تصویربرداری حرارتی\LTRfootnote{Thermography} و ... نیز وجود دارد که به دلیل کاربردهای کیلینیکی کمتر از شرح آن‌ها خودداری می‌شود.
\پایان{فقرات}

در عملیات قطعه‌بندی تصاویر پزشکی به دلیل آن که قطعه‌بندی به طور معمول از روی تصاویر توموگرافی سه‌بعدی صورت می‌گیرد، در ادامه به شرح و بسط بیشتر روش‌های تصویربرداری سی‌تی اسکن و ام‌آرآی پرداخته می‌شود. 
 
\زیرقسمت{تصویربرداری سی‌تی اسکن}

تصویربرداری سی‌تی اسکن یک تکنیک تصویربرداری پزشکی است که در رادیولوژی برای استخراج اطلاعات از بدن به صورت غیرتهاجمی استفاده می‌شود و روند تشخیص را سرعت می‌بخشد. برخلاف دستگاه‌های معمول تصویربرداری پرتوی ایکس، که از یک منبع ثابت پرتوی ایکس استفاده می‌کنند، در سی‌تی اسکن از یک منبع متحرک مجهز به موتور استفاده می‌شود که حول گانتری\زیرنویس{Gantry به محفظه‌ی سیلندری شکل دستگاه سی‌تی اسکن گفته می‌شود که تیوب پرتوی ایکس درون آن قرار می‌گیرد.} دستگاه قابلیت چرخش دارد. در طی تصویربرداری، بیمار بر روی یک تخت قرار می‌گیرد و به آهستگی به داخل گانتری وارد می‌شود؛ در همین حین منبع پرتوی ایکس درون گانتری دور بدن بیمار می‌چرخد و باریکه‌ی پرتوهای اشعه‌ی ایکس از بدن بیمار عبور می‌کند. در سی‌تی اسکن  از آشکارسازهای دیجیتال پرتوی ایکس استفاده می‌شود که دقیقا در مقابل منبع پرتوی‌ ایکس قرار گرفته‌اند و با آشکار سازی اشعه‌ی عبوری از بدن بیمار، یک سیگنال به کامپیوتر ارسال می‌شود. شکل ~\رجوع{شکل:سی‌تی} شمای کلی یک دستگاه سی‌تی اسکن را نشان می‌دهد.

\شروع{شکل}[H]
\centerimg{02ctscan.jpg}{7cm}
\شرح{دستگاه سی‌تی اسکن \مرجع{ct}}
\برچسب{شکل:سی‌تی}
\پایان{شکل}

هر مرتبه که منبع پرتوی ایکس یک چرخش کامل را انجام می‌دهد دستگاه سی‌تی اسکن از تکنیک‌های پیچیده‌ی ریاضیاتی برای ساخت تصویر دو بعدی برای هر لایه از بدن بیمار از روی سیگنال‌های دریافتی انجام می‌دهد. ضخامت این لایه‌ها بستگی به نوع دستگاه سی‌تی اسکن دارد اما به طور معمول بین یک تا ده میلی‌متر از بافت بدن برای هر لایه است. وقتی بازسازی یک لایه به اتمام رسید برروی لایه‌های قبلی انباشته می‌شود و در نهایت یک تصویر سه‌بعدی ساخته می‌شود.

هر لایه از تصویر ساخته‌شده امکان نمایش به صورت مجزا و یا به صورت انباشه شده و سه‌بعدی را دارد که قابلیت نمایش، اسکلت، ساختارها و بافت‌های بدن و همچنین ناهنجاری‌های ایجاد شده در بدن را دارا می‌باشد و امکان تشخیص را برای پزشک مهیا می‌سازد. استفاده از تصاویر سی‌تی در روند تشخیص و درمان فواید زیادی دارد از جمله، توانایی چرخش و جابجایی بین لایه‌های مختلف تصویر که امکان مکان‌یابی موقعیت دقیق ناهنجاری را فراهم می‌سازد. شکل~\رجوع{شکل:نمونه سی‌تی} یک نمونه تصویر از ناحیه‌ی شکم را نشان می‌دهد که در آن ساختارها و بافت‌های مختلف به راحتی قابل تفکیک است.
\شروع{شکل}[H]
\centerimg{02ctexp.png}{7cm}
\شرح{نمونه‌ی تصویر سی‌تی اسکن از ناحیه‌ی شکم در سه نمای مختلف \مرجع{ctsamp}}
\برچسب{شکل:نمونه سی‌تی}
\پایان{شکل}

از سی‌تی اسکن می‌توان در تشخیص بیماری و آسیب نواحی مختلف بدن استفاده نمود به عنوان مثال از سی‌تی در تشخیص تومور و غدد سرطانی و سایر ناهنجاری‌ها در نواحی شکم، سر و گردن و قفسه‌ی سینه بسیار استفاده می‌شود \مرجع{ctexplain}.  

\زیرقسمت{تصویربرداری ام‌آرآی}

ام‌آرآی یا روش تصویربرداری با تشدید مغناطیس یکی از روش های پیشرفته تصویربرداری پزشکی است. با استفاده از این روش میتوان تصویر بافت های درونی بدن را دید و از آن طریق مشکلات و بیماری های اعضای بدن را تشخیص داد.
همانطور که می‌دانیم در روش‌های تصویربرداری با اشعه‌ی ایکس مانند رادیوگرافی ساده و یا سی‌تی اسکن بدن تحت تابش مقدار معینی از اشعه یونیزه کننده قرار می‌گیرد که اگر از حد مشخصی بیشتر باشد می‌تواند موجب اشکالاتی در کارکرد سلول‌ها شود. ولی در ام‌آرآی از اشعه ایکس استفاده‌ای نمی‌شود و بنابراین نسبت به رادیوگرافی و سی‌تی اسکن بسیار کم ضررتر است.

امواج مورد استفاده در ام‌آرآی از جنس امواج رادیویی و مغناطیسی هستند که ضرری برای بدن ندارند. ام‌آرآی از این واقعیت فیزیکی استفاده می‌کند که پروتون‌هایی که در هسته‌ی اتم‌ها قرار گرفته‌اند مانند کره‌ی زمین در حول محور خود با سرعت زیادی می‌چرخند و در نتیجه یک میدان معناطیسی در اطراف خود تشکیل می‌دهند. در ام‌آرآی بیمار در یک میدان مغناطیسی بسیار قوی قرار می‌گیرد. این میدان موجب می‌شود محور چرخش پروتون های هسته‌ی اتم‌ها در تمام بافت‌های بدن (بخصوص پروتون‌هایی که در هسته مولکول آب قرار دارند) در امتداد خطوط میدان مغناطیسی ام‌آرآی قرار گیرند. سپس امواج رادیویی خاصی به سوی بدن بیمار تابانده می‌شود. این امواج که بصورت پالس فرستاده می‌شوند موجب می‌گردند تا محور چرخش پروتون ها کمی تغییر کند. با اتمام پالس رادیویی، محور چرخش پروتون دوباره در امتداد خطوط میدان مغناطیس برمیگردد. این برگشت موجب ایجاد یک موج رادیویی (الکترومغتاطیسی) جدید می‌شود. سپس این امواج رادیویی ثانویه که از تک تک پروتون‌ها ساطع می‌شوند، توسط گیرنده‌های دستگاه ام‌آرآی دریافت شده و به کامپیوتر آن ارسال می‌گردند. کامپیوتر ام‌آرآی بسیار پرقدرت و با توان محاسباتی بالا است. در این کامپیوتر امواج دریافت شده بسرعت تحلیل شده و سپس تصاویری براساس این تحلیل‌ها ساخته می‌شود که پزشک آن‌ها را بر روی مانیتور دستگاه می‌بیند و در صورت لزوم آنها را چاپ می‌کند.

در کامپیوتر ام‌آرآی مشخص می‌شود که در چه نقاطی از بدن موج رادیویی بیشتری ساطع شده است. هرچه شدت موج دریافتی از نقطه‌ای از بدن بیشتر باشد نشانه تراکم بیشتر پروتون در آن نقطه است و چون فراوان‌ترین اتم بدن که پروتون دارد اتم هیدروژن است که در مولکول آب قرار دارد پس هرجایی که موج رادیویی بیشتری ارسال کرده است در واقع آب بیشتری داشته است.
در واقع کاری که ام‌آرآی انجام می‌دهد این است که نشان دهد در چه نقاطی از بدن آب بیشتری وجود دارد. چون غلظت مولکول آب در بافت‌های بدن متفاوت است و با بیمار شدن بافت‌ها این غلظت باز هم تغییر میکند می‌توان با استفاده از اطلاعات دریافتی تصویر بسیار دقیقی از شکل بافت های گوناگون بدن ایجاد کرد.

ام‌آرآی یک روش تصویربرداری دقیق و پرقدرت برای تشخیص مشکلات و بیماری‌های بافت‌های بدن است. یکی از نقاط تمایز این روش با سی‌تی اسکن در این است که در ام‌آرآی تصاویر بافت‌های نرم مانند غضروف، تاندون، عصب و رگ ها بسیار واضح و دقیق دیده می‌شوند و این روش تصویربرداری بخصوص برای تشخیص بیماری های این بافت‌ها مفید است. تصویر حاصل از ام‌آر‌آی مانند تصویر سی‌تی اسکن، سه‌بعدی است و امکان نمایش لایه‌های مختلف وجود دارد. شکل~\رجوع{شکل:ام آر} در سمت چپ یک دستگاه ام‌آی‌آر و در سمت راست یک نمونه تصویر دریافت شده از زانو را نشان می‌دهد که با جزییات بالایی بافت‌ها را از یکدیگر تفکیک کرده است \مرجع{mrexplain}. 

\شروع{شکل}[H]
\centerimg{02mri.png}{7cm}
\شرح{تصویر یک دستگاه ام‌آرآی (سمت چپ) و یک لایه از تصویر سه‌بعدی ام‌آرآی زانو (سمت راست)  \مرجع{mrexplain}}
\برچسب{شکل:ام آر}
\پایان{شکل}

\قسمت{هوش مصنوعی} 
در ادامه‌ی این قسمت به بررسی و تعریف حوزه‌های مرتبط با هوش مصنوعی\LTRfootnote{Artificial Intelligence} پرداخته خواهد شد.

\زیرقسمت{هوش مصنوعی}
هوش مصنوعی به عنوان یک رشته‌ی دانشگاهی در دهه‌ی 50 میلادی پایه‌گذاری شد. در واقع اصطلاح هوش مصنوعی توسط جان مک‌کارتی\LTRfootnote{John McCarthy}، دانشمند علوم کامپیوتر آمرکایی، ابداع شد که طبق تعریف او، هوش مصنوعی عبارت است از علم ساخت ماشین‌های هوشمند به خصوص برنامه‌های کامپیوتری هوشمند.

اگرچه از تعریف هوش مصنوعی چندین دهه می‌گذرد اما رشد و گسترش آن تنها در دو دهه‌ی اخیر به علت در دسترس بودن داده‌های عظیم\LTRfootnote{Big Data} و بالا رفتن توان کامپیوتری میسر شده است. هوش مصنوعی بهترین عملکرد خود را با در کنار هم قرار دادن حجم بالای دادگان و الگوریتم‌های هوشمند بدست می‌آورد که باعث یادگیری ویژگی‌ها و الگوهای درون دادگان به صورت خودکار می‌شود. از جمله کاربردهای روز افزون هوش مصنوعی که تقریبا با زندگی همه‌ی ما آمیخته شده است می‌توان به: ماشین‌های خودران، دستیاران صوتی، تشخیص هوشمند چهره برای شناسایی افراد، پروژه‌های وابسته به ژن‌های انسان و ... اشاره نمود.

اگرچه بسیاری از افراد اصطلاحات هوش مصنوعی، یادگیری ماشین و یادگیری عمیق را به‌جای یکدیگر استفاده می‌کنند اما در واقع این اصطلاحات تعاریف دقیق‌تر و جداگانه‌ای از یکدیگر دارند. همانطور که پیشتر اشاره شد هوش مصنوعی علم ایجاد ماشین‌ها و برنامه‌های کامپیوتری هوشمند است که همانطور که از این تعریف نیز پیداست حوزه‌ی بسیار وسیعی را دربر می‌گیرد که امروزه تقریبا هر شرکتی ادعای استفاده از هوش مصنوعی در محصولات خود را داراست. بنابراین یادگیری ماشین در زیرمجموعه‌ی هوش مصنوعی قرار می‌گیرد و شامل تکنیک‌های و مدل‌های بسیار پیشرفته‌تر که کامپیوترها را قادر به استخراج ویژگی‌های دقیق‌تر از دادگان می‌سازد و به الگوریتم هوش مصنوعی تحویل می‌دهد. به طور خلاصه می‌توان گفت یادگیری ماشین علم قرار دادن کامپیوترها در عمل است بدون آن که به‌طور صریح برنامه‌ریزی شده باشند.

در نهایت، یادگیری عمیق یک حوزه‌ی جدید یادگیری ماشین است که از شبکه‌های عصبی عمیق و چند لایه برای استخراج ویژگی و تصمیم‌گیری استفاده می‌کند که این کار موجب استخراج الگوها و ویژگی‌های مرتبه‌ی بالاتر و تفکیک‌گر بهتر می‌شود و در نتیجه دقت الگوریتم افزایش پیدا خواهد کرد. از جمله کاربرد‌های یادگیری عمیق می‌توان به طبقه‌بندی اشیا در تصاویر\LTRfootnote{Object Classification}، شناسایی اشیا در تصاویر\LTRfootnote{Object Recognition}، ترجمه از یک زبان به زبان دیگر\LTRfootnote{Language Translation}، تولید تصاویر ساختگی\LTRfootnote{Fake Image Generation} و ... اشاره نمود \مرجع{helm2020machine}. 

به طور کلی می‌توان ارتباط حوزه‌های هوش مصنوعی، یادگیری ماشین و یادگیری عمیق را به صورت شکل~\رجوع{شکل:هیب} نشان داد. همانطور که ملاحظه می‌شود حوزه‌های یادگیری ماشین و یادگیری عمیق در زیر مجموعه‌ی هوش مصنوعی واقع می‌شود و حوزه‌ی بینایی کامپیوتر علاوه بر داشتن مفاهیم خاص خود در سال‌های اخیر اشتراک نسبتا زیادی با روش‌های هوش مصنوعی پیدا کرده است (در ادامه به بررسی حوزه‌ی بینایی کامپیوتر پرداخته خواهد شد).

\شروع{شکل}[H]
\centerimg{02aichart.png}{7cm}
\شرح{ارتباط حوزه‌های هوش مصنوعی، یادگیری ماشین، یادگیری عمیق و بینایی کامپیوتر}
\برچسب{شکل:هیب}
\پایان{شکل}


\زیرقسمت{یادگیری ماشین}
یادگیری ماشین شامل سه نوع حوزه‌ی یادگیری است که عبارتند از: یادگیری با سرپرست\LTRfootnote{Supervised Learning}، یادگیری بدون سرپرست\LTRfootnote{Unsupervised Learning} و یادگیری تقویتی\LTRfootnote{Reinforcement Learning}، که هدف نهایی این الگوریتم‌ها فراگیری ویژگی‌ها و الگوها از دادگان است بدون آنکه به صورت صریح به این ویژگی‌ و الگوها اشاره شده باشد.

\زیرزیرقسمت{یادگیری با سرپرست}
در یادگیری با سرپرست، خروجی مطلوب یا داده‌های \lr{Ground Truth} در دسترس هستند و در نتیجه با تشکیل یک تایع هزینه بین خروجی مطلوب و خروجی پیش‌بینی شده، با استفاده از روش‌های آموزش مدل‌های یادگیری ماشین الگوریتم آموزش می‌بیند. خروجی مطلوب تعریف شده بسته به وظیفه‌ی مورد نظر می‌تواند گسسته (شماره‌ی مربوط به کلاس‌های مختلف دادگان) و یا یک خروجی پیوسته باشد بر این اساس یادگیری با سرپرست را می‌توان به دو گروه طبقه‌بندی\LTRfootnote{Classification} و رگرسیون\LTRfootnote{Regression} تقسیم نمود.

\شروع{فقرات}
\فقره طبقه‌بندی: در الگوریتم‌های طبقه‌بند هدف نسبت دادن یک مشاهده‌ به کلاس‌های تعریف شده است به عنوان مثال طبقه‌بندی تصاویر تومور پوستی به دو گروه خوش‌خیم و بدخیم یک طبقه‌بندی دو کلاسه است و یا طبقه‌بندی ایمیل‌های دریافتی به دو کلاس‌ ایمبل‌های هرز و ایمیل‌های سالم نیز نمونه‌ای از انجام طبقه‌بندی با روش‌های یادگیری ماشین با سرپرست است.

\فقره رگرسیون: در این نوع مسایل به پیش‌بینی یک مقدار پیوسته نیاز است که در نتیجه خروجی مدل باید یک مقدار پیوسته باشد، به عنوان مثال پیش‌بینی قیمت خانه از روی متراژ، سال ساخت، منطقه‌ی ساخت و ... یک مساله‌ی رگرسیون است.
\پایان{فقرات}
برای مقایسه‌ی بهتر این دو گروه، شکل~\رجوع{شکل:کلاسرگرس} تصویر کاملی از تفاوت هدف این دو الگوریتم را به نمایش کشیده است. برای طبقه‌بندی، هدف یافتن مرزی است که کلاس‌های مختلف را از هم جدا می‌کند اما در مساله‌ی رگرسیون هدف پیدا کردن یک منحنی است که بهترین تخمین ار دادگان را داشته باشد.

\شروع{شکل}[H]
\centerimg{02class_reg.png}{10cm}
\شرح{مقایسه‌ی الگوریتم‌های طبقه‌بندی و رگرسیون \مرجع{classReg}}
\برچسب{شکل:کلاسرگرس}
\پایان{شکل}

\زیرزیرقسمت{یادگیری بدون سرپرست}
در این نوع از الگوریتم‌های یادگیری خروجی مطلوب در دسترس نیست و یک یادگیری بدون بازخورد است. این نوع یادگیری برای استخراج الگوی و پیوندهای خاص نامعلوم بین دادگان دردسترس، استفاده می‌شود. با تعریف ارایه شده می‌توان این نوع یادگیری را به دو کلاس خوشه‌بندی\LTRfootnote{Clustering} و تشخیص رابطه\LTRfootnote{Association} تقسیم نمود.

\شروع{فقرات}
\فقره خوشه‌بندی: در این نوع یادگیری بدون سرپرست هدف پیدا کردن خوشه‌هایی بین دادگان موجود است به ‌طوریکه داده‌های قرار گرفته در این خوشه‌ها دارای ویژگی‌های یکسان باشند. به عتوان مثال با در دست داشتن کل اخبار خبر‌های حوزه‌های مختلف از یکدیگر تفکیک داده شوند.

\فقره تشخیص رابطه: هدف در تشخیص رابطه پیدا کردن قانونی است که اکثر دادگان در دسترس، از آن پیروی می‌کنند. به عنوان مثال الگوریتم‌های توصیه کننده در خرید‌های اینترنتی محصولاتی که احتمال خرید بیشتری بر اساس جستجوهای قبلی را دارند، نمایش می‌دهند.
\پایان{فقرات}

\زیرزیرقسمت{یادگیری تقویتی}
در این نوع یادگیری به‌جای استفاده از داده‌های علامت‌گذاری شده و مطلوب از الگوریتم‌های مبتنی بر پاداش و مجازات استفاده می‌شود. به عنوان مثال یک کودک را در نظر بگیرید که برای اولین بار قصد راه رفتن دارد. این کودک اگر به زمین بیفتد ممکن است آسیب ببیند ولی اگر بتواند راه برود با تشویق والدین مواجه می‌شود بنابراین با سعی در بیشینه کردن پاداش خود که همان تشویق و آغوش والدین است و با سعی و خطا اقدام به یادگیری می‌کند. با الگو برداری از چنین روندی الگوریتم‌های یادگیری تقویتی توسعه پیدا کرده‌اند که با سعی و خطا و مشاهدات فراوان، هدف بیشینه کردن پاداش است که در نهایت به یادگیری الگوریتم برای انجام یک عملیات می‌انجامد. 

\زیرقسمت{یادگیری عمیق}
همانند یادگیری ماشین، یادگیری عمیق نیز یک متد یادگیری آماری است که وظیفه‌ی استخراج ویژگی از دادگان خام را دارد. تفاوت اصلی یادگیری عمیق با یادگیری ماشین در استخراج ویژگی توسط شبکات عصبی چند لایه با تعداد زیاد لایه‌های میانی\LTRfootnote{Hidden Layers} است که پشت سر هم قرار گرفته‌اند. همچنین الگوریتم‌های یادگیری عمیق نسبت به یادگیری ماشین پیچیده‌تر و نیازمند قدرت پردازش بالاتری هستند. بنابراین همانطور که پیشتر اشاره گردید، با افزایش تعداد دادگان در دسترس و بالا رفتن قدرت پردازش این حوزه از هوش مصنوعی در دهه‌ی اخیر رشد بسیار چشم‌گیری داشت.

در تعاریف یادگیری عمیق دیدیم که این حوزه زیر مجموعه‌ی یادگیری ماشین قرار می‌گیرد بنابراین تمام متدها و حوزه‌های یادگیری، در یادگیری ماشین، در یادگیری عمیق نیز کاربرد دارد (یادگیری با و بدون سرپرست و یادگیری تقویتی). در ادامه به معرفی چند مدل پر استفاده در حوزه‌ی یادگیری عمیق پرداخته می‌شود.

 \زیرزیرقسمت{شبکه‌های عصبی پرسپترون چند لایه}
چگونه یک فرد تفاوت میان سگ و گربه را درک می‌کند؟ برای پاسخ به این سوال باید به سراغ بیولوژی شبکه‌ی نورونی داخل مغز برویم. درون مغز انسان به صورت تقریبی حدود 10 میلیارد نورون وجود دارد که هریک از این نورون‌ها به حدود 10 هزار نورون همسایه‌ی خود متصل‌اند. این اتصالات بسیار زیاد و تعداد هنگفت نورون‌ها باعث استخراج ویژگی و یادگیری الگو در داده‌های ورودی حسگرهای بدن می‌شود و بنابراین یک شخص با این ابزار می‌تواند تفاوت میان سگ و گربه را بفهمد و این دو را تفکیک کند.


هر یک از این نورون‌ها سیگنال‌های الکتروشیمیایی را توسط دندریت‌های\LTRfootnote{Dendrites} خود از سایر نورون‌ها دریافت می‌کند و درصورتی که ولتاژ غشای نورون از یک آستانه عبور کند سیگنال‌های دریافتی را توسط آکسون\LTRfootnote{Axon} خود به سایر نورون‌ها انتقال می‌دهد. برخلاف تلاش‌های فراون صورت گرفته برای شناخت عملکرد مغز، هنوز مدل دقیقی برای مطالعه‌ی عملکرد این مجموعه نورونی عظیم ارایه نشده است اما مدل‌سازی یک تک نورون توسط هاچکین-هاکسلی \مرجع{hodgkin1952quantitative} با دقت خوبی ارایه شد. در حوزه‌ی شبکه‌های عصبی مصنوعی از یک مدل بسیار ساده‌تر از مدل هاچکین-هاکسلی استفاده می‌شود که به آن پرسپترون\LTRfootnote{Perceptron} گفته می‌شود. در شکل ~\رجوع{شکل:نورو} یک نورون بیولوژیکی در کنار یک مدل بسیار ساده از نورون نشان داده شده است.

\شروع{شکل}[H]
\centerimg{02BvsAneuron.jpg}{13cm}
\شرح{مقایسه‌ی یک نورون طبیعی و مدلسازی ساده‌ی آن \مرجع{njogholo2018investigating}}
\برچسب{شکل:نورو}
\پایان{شکل}

در این مدل پرسپترون چند نکته حایز اهمیت وجود دارد:
\شروع{فقرات}
\فقره ورودی: در گره‌های ورودی پرسپترون که به نوعی دندریت‌های نورون هستند مقادیر حقیقی به عنوان میزان عملکرد نورون‌های همسایه به ورودی داده می‌شود. این مقادیر به عنوان مثال می‌تواند شدت روشنایی پیکسل‌های یک تصویر باشد.

\فقره وزن‌ها: هر ارتباط که از ورودی به این پرسپترون می‌رسد، دارای یک وزن خاص است که می‌تواند هر مقدار حقیقی‌ای باشد. در واقع در روند یادگیری این وزن‌ها هستند که تغییر می‌کنند و نیازمند محاسبات هستند و در نهایت با بدست آمدن وزن‌های بهینه وظیفه‌ی مورد نظر توسط شبکه‌ی عصبی انجام می‌شود.

\فقره جمع وزن‌دار: پس از آنکه ورودی به پرسپترون داده می‌شود یک جمع وزن‌دار با توجه به وزن ارتباطات نورونی صورت می‌گیرد و یک مقدار حقیقی بدست می‌آید.

\فقره تابع فعالیت\LTRfootnote{Activation Function}: همانند یک نورون طبیعی که باید ولتاژ آن از یک آستانه عبور کند تا به اصطلاح آتش کند، یک تابع فعالیت بر سر راه جمع وزن‌دار قرار می‌گیرد تا این مدلسازی صورت گیرد.

\فقره خروجی: در نهایت پس از اعمال تابع فعالیت خروجی نهایی پرسپترون ایجاد می‌شود.
\پایان{فقرات}

با قرار دادن تعدادی از این مدل‌های پرسپترون در کنار یکدیگر می‌توان یک شبکه‌ی عصبی ساخت. اگر تعداد لایه‌های زیاد باشد به آن شبکه عصبی عمیق گفته می‌شود. شکل ~\رجوع{شکل:شد} دو شبکه‌ی تمام متصل کم عمق (سمت چپ) وعمیق (سمت راست) را نشان می‌دهد. 
\شروع{شکل}[H]
\centerimg{02shallowdeep.jpg}{13cm}
\شرح{مقایسه‌ی شبکه‌ی پرسپترون عمیق و کم عمق \مرجع{johnson2019survey}}
\برچسب{شکل:شد}
\پایان{شکل}

\زیرزیرقسمت{شبکه‌های عصبی کانوولوشنی}
این نوع از شبکات از جمله محبوب‌ترین مدل‌ها یادگیری عمیق برای پردازش تصویر و ویدیو در حوزه‌های پردازش تصویر و بینایی کامپیوتر هستند. به دلیل آنکه در این پروژه از این نوع شبکه‌ها استفاده‌ی بسیار زیادی شده است در بخش بعدی با جزییات بررسی خواهد شد.

\زیرزیرقسمت{شبکه‌های عصبی بازگشتی}
به زبان ساده، شبکه‌های عصبی بازگشتی\LTRfootnote{Recurrent Neural Networks} برای پیش‌بینی وقایع و استخراج ویژگی از ورودی‌های قبلی استفاده می‌کنند. به عنوان مثال اگر بخواهیم حرف اخر یک کلمه را پیش‌بینی کنیم منطقی است که حروف‌های ابتدایی آن کلمه را در حافظه قرار دهیم و با استفاده از اطلاعات آن‌ها اقدام به پیش‌بینی نهایی کنیم. بنابراین شبکه‌های عصبی بازگشتی امکان به ‌خاطرسپاری ورودی‌های گذشته را فراهم می‌سازد که این ویژگی این نوع شبکات را از دیگر مدل‌ها متمایز می‌سازد. کاربرد این مدل‌ها برای داده‌های متوالی مانند حوزه‌ی پردازش زبان طبیعی\LTRfootnote{Natural Language Processing}، پیش‌بینی سیگنال‌های بازار سرمایه، تولید موسیقی و ... می‌باشد.

\زیرزیرقسمت{شبکه‌های مولد خصمانه}
شبکه‌های عصبی مولد خصمانه\LTRfootnote{Generative Adversarial Networks (GAN)} در سال 2014 توسط گودفلو \مرجع{goodfellow2014generative} ارایه شد. این نوع مدل‌ها برخلاف مدل‌های دیگر که فقط از دادگان برای یادگیری، ویژگی استخراج می‌کردند، امکان خلق کردن بر اساس دادگان ایجاد گردید. این نوع مدل‌ها از دو شبکه‌ی عصبی تشکیل شده‌اند: شبکه‌ی مولد\LTRfootnote{Generator} و شبکه‌ی نقاد\LTRfootnote{Discriminator}. شبکه‌ی مولد یک نویز در ورودی می‌گیرد و با سعی در تخمین توزیع داده‌های آموزش، یک تصویر جعلی ایجاد می کند. در دست دیگر شبکه‌ی نقاد سعی در شناسایی داده‌های جعلی از داده‌های حقیقی را دارد. بنابراین یک رقابت بین مولد برای فریب دادن نقاد و نقاد برای تفکیک داده‌های جعلی و حقیقی صورت می‌گیرد. 

شکل ~\رجوع{شکل:گن} چگونگی رقابت بین مولد و نقاد را نشان می‌دهد. همان‌طور که ملاحظه می‌شود، شبکه‌ی نقاد از دو سمت ورودی دریافت می‌کند (داده‌های جعلی و داده‌های حقیقی). در نهایت با تکمیل روند آموزش، شبکه‌ی مولد آنقدر حرفه‌ای می‌شود که با دقت بالایی می‌تواند داده‌هایی تولید کند که نقاد قادر به تشخیص آن از داده‌های حقیقی نباشد. کاربرد این مدل‌ها در خلق دادگان جدید مانند ایجاد تصاویر ساختگی، تولید موسیقی، تولید صدای طبیعی انسان و ... است \مرجع{aiexplain}.

\شروع{شکل}[H]
\centerimg{02gan.jpg}{13cm}
\شرح{شبکه‌های مولد خصمانه \مرجع{cai2020utilizing}}
\برچسب{شکل:گن}
\پایان{شکل}
 
\قسمت{شبکه‌های عصبی کانوولوشنی عمیق}
شبکه‌های عصبی کانوولوشنی بسیار مشابه با شبکه‌های تمام متصل و پرسپترون چند لایه هستند که از نورون‌های شامل وزن و بایاس تشکیل شده‌اند. هر نورون‌ یک ورودی دریافت می‌کند و سپس با اعمال یک ضرب داخلی بین ورودی و وزن‌های خود و در ادامه اضافه کردن یک تابع غیرخطی (تابع فعالیت) خروجی خود را تولید می‌کند. در این حالت، تمام شبکه به عنوان یک تایع مشتق‌پذیر عمل می‌کند و در نهایت با ایجاد خروجی و تشکیل تابع هزینه با استفاده از الگوریتم \lr{Back Propagation} شبکه وظیفه‌ی مورد نظر را یاد می‌گیرد.

در شبکه‌های تمام متصل، به تعداد المان‌های ورودی نورون در لایه‌ی ورودی قرار می‌گیرد و در ادامه چندین لایه‌ی مخفی که تمامی نورون‌های هر لایه به لایه‌ی قبل و بعد خود متصل‌اند، بر روی این ورودی فعالیت می‌کنند تا خروجی نهایی تولید گردد. بنابراین با افزایش اندازه‌ی ورودی و نیز تعداد لایه‌ها، تعداد وزن‌هایی که باید در آن‌ها یادگیری صورت گیرد بسیار زیاد خواهند شد. با ظهور شبکه‌های کانوولوشنی علاوه بر رفع مشکل تغییر تعداد پارامترها با تغییر اندازه‌ی ورودی، پیش‌بینی نهایی نسبت به جابجایی و دیگر انتقالات درون تصویر، مقاوم شد. در شبکه‌های کانوولوشنی برخلاف شبکه‌های تمام متصل، نورون‌ها در سه بعد، طول\LTRfootnote{Height} و عرض\LTRfootnote{Width} و عمق\LTRfootnote{Depth} چیده شده‌اند و با حرکت بر روی تصویر و استخراج ویژگی از آن خروجی نهایی را ایجاد می‌کنند. شکل ~\رجوع{شکل:سینن} ویژگی‌های استخراج شده از یک تصویر ورودی (حجم قرمز رنگ در تصویر) را نشان می‌دهد که چون نورون‌ها در سه بعد چیده شده‌اند ویژگی‌های استخراج شده نیز سه‌بعدی هستند. با مقایسه‌‌ی این شکل و شکل ~\رجوع{شکل:شد}  تفاوت دو شبکه‌ی کانوولوشنی و تمام متصل در ابعاد ویژگی‌های استخراج شده مشخص است.

\شروع{شکل}[H]
\centerimg{02cnn.jpeg}{11cm}
\شرح{ماتریس‌ ویژگی‌های سه بعدی استخراج شده توسط یک شبکه‌ی کانوولوشنی \مرجع{cnnexplain}}
\برچسب{شکل:سینن}
\پایان{شکل}

اولین کاربرد شبکه‌های کانوولوشنی در طبقه‌بندی تصاویر صورت گرفت و پر استفاده‌ترین شبکه‌ها در این حوزه از معماری با لایه‌های کانوولوشن، توابع فعالیت، لایه‌های ادغام\LTRfootnote{Pooling Layers} و لایه‌های تمام متصل برای طبقه‌بندی استفاده می‌شود. در شکل ~\رجوع{شکل:دستسینن} معماری یک شبکه‌ی طبقه‌بند برای طبقه‌بندی اعداد دست‌نویس مشاهده می‌شود که در ادامه به توضیح مختصر هر یک از لایه‌های استفاده شده می‌پردازیم.
\شروع{شکل}[H]
\centerimg{02cnndigit.jpeg}{11cm}
\شرح{معماری یک شبکه‌ی کانوولوشنی برای طبقه‌بندی اعداد دست‌نویس \مرجع{cnnexplain2}}
\برچسب{شکل:دستسینن}
\پایان{شکل}

\زیرقسمت{لایه‌های کانوولوشنی}
لایه‌های کانوولوشنی شامل یکسری فیلترهایی هستند که با عمق ماتریس ویژگی برابری می‌کنند اما طول‌ و عرض این فیلترها کوچکتر است و بنابراین با لغزاندن بر روی ماتریس ویژگی و در واقع محاسبه‌ی همبستگی\LTRfootnote{Correlation} به جای کانوولوشن، ماتریس ویژگی جدید محاسبه‌ می گردد. به عنوان مثال، اگر ابعاد تصویر ورودی $100*100*3$ باشد حتما عمق فیلتر باید با عمق تصویر برابر باشد بنابریان فیلتر می‌تواند ابعاد $5*5*3$ داشته باشد. شکل ~\رجوع{شکل:کانولایر} یک ماتریس ویژگی و حرکت یک فیلتر بر روی آن‌را در یک لایه‌ی کانوولوشنی را نشان می‌دهد
\شروع{شکل}[H]
\centerimg{02convlayer.png}{3cm}
\شرح{چگونگی حرکت فیلتر در یک لایه‌ی کانوولوشنی \مرجع{cnnexplain2}}
\برچسب{شکل:کانولایر}
\پایان{شکل}
برای درک بهتر چگونگی محاسبات در یک لایه‌ی کانوولوشنی، شکل ~\رجوع{شکل:کانولایر2} را در نظر بگیرید. همانطور که پیشتر گفته شد، عمق فیلتر و عمق تصویر باید برابر باشد (در اینجا 3) سپس با لغزیده شدن فیلتر بر روی تصویر مشابه شکل قبل و انجام یک ضرب نقطه‌ای و مجموع‌گیری بین سه کانال و در نهایت اضافه کردن بایاس به مقدار بدست آمده، مقدار خروجی فیلتر محاسبه می‌شود.
\شروع{شکل}[H]
\centerimg{02convlayer2.png}{15cm}
\شرح{روند محاسبات در یک لایه‌ی کانوولوشنی \مرجع{cnnexplain2}}
\برچسب{شکل:کانولایر2}
\پایان{شکل}

\زیرقسمت{توابع فعالیت}
همانطور که در بخش‌های قبل گفته شد، یک نورون طبیعی با رسیدن به ولتاژ آستانه آتش می‌کند بنابراین برای شبیه‌سازی این رفتار از یک تابع فعالیت استفاده می‌شود. تابع فعالیت در واقع تصمیم می‌گیرد که نورون مدل‌سازی شده با چه مقادیری فعایت کند و میزان فعالیت آن در شکل‌گیری خروجی نهایی چه‌مقدار باشد. همیچنین تابع فعایت چون غیر خطی است، امکان تخمین و استخراج ویژگی‌های غیر خطی توسط شبکه فراهم می‌شود. شکل ~\رجوع{شکل:اکتیویشن} چهار نمونه از پر استفاده‌ترین توابع فعالیت در شبکه‌های عمیق را نشان می‌دهد که عبارتند از: ,Tanh
ReLU\LTRfootnote{Rectified Linear Unit},
 Sigmoid و .Identity به دلیل آنکه در شبکه‌های عمیق با مشکل محو شدن گرادیان مواجهیم بنابراین استفاده از ReLU برای رفع این مشکل بسیار بیشتر است.
\شروع{شکل}[H]
\centerimg{02activationfunc.png}{12cm}
\شرح{چهار نمونه از پر استفاده‌ترین توابع فعالیت \مرجع{actfunc}}
\برچسب{شکل:اکتیویشن}
\پایان{شکل}

\زیرقسمت{لایه‌های ادغام}
لایه‌های ادغام وظیفه‌ی کاهش ابعاد ماتریس‌های ویژگی استخراج شده توسط لایه‌های کانوولوشنی را دارند که این کار باعث کاهش حجم محاسبات مورد نیاز و افزایش سرعت خواهد شد. علاوه بر این الن لایه‌ها ویژگی‌های غالب را استخراج می‌کنند که نسبت به دوران و جابجایی مقاوم هستند. نحوه‌ی عملکرد لایه‌های ادغام مانند لایه‌های کانوولوشنی است و بر روی ماتریس ویژگی لغزانیده می‌شود، با این تفاوت که در لایه‌های ادغام محاسبات نسبت به لایه‌های کانوولوشنی متفاوت است. در شکل ~\رجوع{شکل:پوول} دو نوع از پر استفاده‌ترین لایه‌های ادغام نشان داده شده است، ادغام میانگین‌گیر\LTRfootnote{َAverage Pooling} و ادغام بیشینه‌گیر\LTRfootnote{Max Pooling}. اندازه ی فیلترهای ادغام $2*2$ است و با گام 2 بر روی ماتریس ویژگی لغزانیده شده‌اند. در ادغام میانگین‌گیر، بین 4 عدد موجود در فیلتر میانگین‌گیری می‌شود و در ادغام بیشینه‌گیر، بیشینه به خروجی می‌رود.
\شروع{شکل}[H]
\centerimg{02poollayer.png}{8cm}
\شرح{ادغام میانگین‌گیر و ادغام بیشینه‌گیر \مرجع{cnnexplain2}}
\برچسب{شکل:پوول}
\پایان{شکل}

\زیرقسمت{لایه‌های تمام متصل}
لایه‌های تمام متصل در بخش‌ شبکه‌های پرسپترون چند لایه معرفی شد. به طور معمول این لایه‌ها برای طبقه‌بندی با استفاده از ویژگی‌های استخراج شده از دادگان استفاده می‌شوند. پیش از ظهور شبکه‌های عصبی عمیق که خودشان ویژگی‌های لازم را استخراج می‌کنند،در روش‌های یادگیری ماشین، ویژگی‌های یک مجموعه داده به صورت دستی و یا با روش‌های کلاسیک استخراج می‌شد و با استفاده از شبکه‌های تمام متصل وظیفه‌ی طبقه‌بندی تکمیل می‌شد. در شبکه‌های کانوولوشنی این ویژگی‌ها توسط لایه‌های کانوولوشن و ادغام استخراج می‌شود و در نهایت با دادن این ویژگی‌ها به لایه‌های تمام متصل کار طبقه‌بندی انجام می‌شود\مرجع{cnnexplain}. لایه‌های آخر شکل ~\رجوع{شکل:دستسینن} این لایه را نشان می‌دهد.

از جمله شبکه‌های موفق کانوولوشنی در حوزه‌ی طبقه‌بندی تصاویر طبیعی می‌توان به AlexNet که در سال 2012 ارایه شد و انقلاب شبکه‌های عمیق را آغاز کرد، اشاره نمود \مرجع{krizhevsky2012imagenet}. پس از ارایه‌ی این مدل، معماری‌های جدید و روش‌های تعمیم‌پذیری\LTRfootnote{َRegularization Terms} زیادی ارایه گردید که نتایج را در زمینه‌ی طبقه‌بندی تصاویر حتی از انسان نیز بهتر کرد. از جمله‌ی این معماری‌ها می‌توان به معماری‌های
 VGGNet ,
 GoogleNet ,
 ResNet
  و ... اشاره نمود \مرجع{wang2019development}. 
  
\قسمت{روش‌های تعمیم‌پذیری}
به هرگونه تکنیکی که قدرت تعمیم مدل را افزایش می‌دهد و خطای تعمیم پذیری را کم می کند، روش تعمیم‌پذیری گفته می‌شود. از جمله‌ی این روش‌ها می‌توان به موارد زیر اشاره نمود:
\begin{multicols}{2}
	\شروع{فقرات}
	\فقره جریمه‌ی وزن‌های شبکه\LTRfootnote{َParameter (weights) Penalties} 
	\فقره افزایش مجموعه دادگان\LTRfootnote{َDataset Augmentation}  
	\فقره مقاومت در برابر نویز\LTRfootnote{َNoise Robustness (input/output)}  
	\پایان{فقرات}
	
	\شروع{فقرات}
	\فقره توقف زود هنگام\LTRfootnote{َEarly Stopping}  
	\فقره روش Dropout
	\فقره روش Batch-Normalization
	\پایان{فقرات}
	
\end{multicols}
در ادامه به معرفی مختصر هر یک از این روش‌ها پرداخته خواهد شد.
\زیرزیرقسمت{جریمه‌ی وزن‌های شبکه}
برای جلوگیری از یادگیری بیش‌ازحد\LTRfootnote{Overfitting} بر روی داده‌های آموزش یکی از روش‌ها، جریمه‌ی وزن‌های شبکه است به این صورت که با اضافه‌کردن یک جمله به تابع هزینه‌ی شبکه، که آن جمله می‌تواند نرم اول یا دوم وزن‌های شبکه باشد؛ از بزرگ شدن بیش از حد وزن‌ها جلوگیری می‌کند و همچنین با کاهش پیچیدگی مدل، قدرت تعمیم‌پذیزی آن بالا می‌رود.
\زیرزیرقسمت{افزایش مجموعه دادگان}
در مدل‌های عصبی، هرچقدر تنوع و تعداد دادگان بیشتر باشد در نهایت مدل بهتر آموزش می‌بیند بنابراین روش‌هایی برای افزایش تعداد دادگان پیشنهاد شده است که به عنوان مثال می‌توان به دوران با زوایای تصادفی، چرفش عمودی و افقی، تغییرات شدت روشنایی و ... اشاره نمود.
\زیرزیرقسمت{مقاومت در برابر نویز}
با اضافه کردن نویز به ورودی یا خروجی مدل و بالا بردن عدم قطعیت، شبکه سعی در استخراج ویژگی‌های مقاوم‌تری می‌کند و در نتیجه مدل نهایی قدرت تعمیم‌پذیری بالاتری دارد \مرجع{zhang2021understanding}.

\زیرزیرقسمت{توقف زود هنگام}
اگر دادگان آموزش را به دو مجموعه داده‌ی آموزش و ارزیابی تقسیم کنیم (برروی دادگان آموزش وزن‌های شبکه تغییر می‌کنند و دادگان ارزیابی در تغییر وزن‌ها نقشی ندارند) و در انتهای هر epoch\زیرنویس{به هر بار آموزش یک مدل بر روی کل مجموعه دادگان یک epoch گفته می‌شود.} مقدار خطای شبکه را برای این دو گروه محاسبه کنیم نموداری مشابه شکل زیر بدست می‌آید که نشان می‌دهد پس از مدتی، شبکه در حال حفظ کردن دادگان آموزش است و خطای دادگان آموزش افزایش می‌یابد بنابراین قدت تعمیم‌پذیری شبکه در حال کم‌شدن است. به توقف روند آموزش بعد از مشاهده روند افزایشی خطای تعمیم‌پذیری، توقف زود هنگام گفته می‌شود.

\شروع{شکل}[H]
\centerimg{02earlystopping.png}{8cm}
\شرح{توقف زود هنگام با توجه به خطای داده‌های ارزیابی \مرجع{genccay2001pricing}}
\برچسب{شکل:ارلی}
\پایان{شکل}

\زیرزیرقسمت{روش Dropout}
اگر در یک مدل عصبی دو نورون ویژگی‌هایی که استخراج می‌کنند مشابه باشند و یا همبستگی بالایی داشته باشند این شبکه به صورت کارآمد عمل نمی‌کند. برای رفع این مشکل تکنیک dropout پیشنهاد شد که با یک درصد احتمال در هر تکرار آموزش، تعدادی از نورون‌ها را غیر فعال می‌کند بنابراین نورنو‌های دخیل در روند آموزش مجبور به یادگیری ویژگی‌های مستق از هم و کارآمدتر هستند و در نتیجه قدرت تعمیم‌پذیر مدل افزایش پیدا می‌کند. در شکل ~\رجوع{شکل:دراپوت} یک شبکه با و بدون استفاده از dropout نشان داده شده است که در استفاده از dropout تعدادی از نورون‌ها حذف شده‌اند و نورون‌های باقی مانده مجبور به استخراج ویژگی‌های کارآند برای پیشبینی نتیجه‌ی مطلوب هستند.

\شروع{شکل}[H]
\centerimg{02dropout.png}{8cm}
\شرح{چگونگی اعمال تکنیک dropout \مرجع{srivastava2014dropout}}
\برچسب{شکل:دراپوت}
\پایان{شکل}

\زیرزیرقسمت{روش Batch-Normalization}
این متد مشکل ناهمگونی تابع چگالی احتمال داده‌ها در لایه‌های میانی را حل می‌کند. این مشکل به این صورت پدید می‌آید که در هر batch از داده‌ها، در روند آموزش یک توزیع احتمال پدید می‌آید که این توزیع‌های احتمال با یکدیگر متفاوت‌اند. مشکل مهمتر آنکه، این ناهمگونی توزیع‌ها در  خروجی لایه‌های شبکه نیز پدید می‌آید. برای رفع این مشکل تکنیک Batch-Normalization معرفی گردید که ابتدا تمام توزیع‌ها را با توجه به میانگین و انحراف معیارشان نرمال‌سازی می‌کنند و سپس با یک‌سری پارامتر‌های قابل یادگیری این توزیع‌ها را تغییر می‌دهند تا یکسان‌سازی نهایی صورت پذیرد \مرجع{ioffe2015batch}. 

\قسمت{پردازش تصویر و بینایی کامپیوتر}
چشم انسان از تعداد بسیار زیادی سلول حساس به نور تشکیل شده‌است که با دریافت نور محیطی و پردازش آن باعث ایجاد یک درک از محیط و اشیای اطراف می‌شود. این روند علی‌رغم اینکه برای انسان بسیار ساده است اما برای یک ماشین تا بتواند درک از تصویر دریافت شده داشته باشد، بسیار پیچیده است. بنابراین زمینه‌های مختلفی برای پردازش و ایجاد درک از تصویر دیجیتال برای ماشین‌ها ایجاد شده است.

در بینایی کامپیوتر مشابه قدت بینایی انسان، هدف ایجاد درک و فهم عمیق یک تصویر یا یک ویدیو است اما پردازش تصاویر دیجیتال،پردازش تصاویر با استفاده از یک کامپیوتر است. این پردازش‌ها می‌تواند شامل بهبود کیفیت تصویر و حذف نویز با فیلتر کردن تصویر و دستکاری شدت‌های آن باشد. بنابراین زمیه‌ی پردازش‌ تصویر زیر مجموعه‌ی بینایی کامپیوتر قرار می‌گیرد. 

حوزه‌ای بینایی کامپیوتر مرتبط با مبحث هوش مصنوعی و یادگیری ماشین است که با هدف ایجاد چارچوب‌های لازم برای پیاده‌سازی قابلیت بینایی در کامپیوترها و سیستم‌های کامپیوتری شکل گرفته‌ است. دانشمندان فعال در حوزه بینایی کامپیوتر، سعی در تولید تکنیک‌ها و روش‌هایی دارند که مفهوم دیدن را برای یک کامپیوتر تعریف می‌کنند. از این طریق، کامپیوترها توانایی شناسایی و درک محتوای موجود در تصاویر دیجیتال و ویدیو‌ها را پیدا می‌کنند \مرجع{computervision}.

\قسمت{جمع‌بندی}
در این فصل با مفاهیم اولیه‌ی این مطالعه آشنایی پیدا شد. در ابتدا مفاهیم تصویربرداری پزشکی معرفی گردید و دو نوع تصویربرداری پرکاربرد (ام‌آزآی و سی‌تی اسکن) برای تشخیص و درمان به صورت دقیق‌تر بررسی شد. در ادامه مفاهیم هوش مصنوعی، یادگیری ماشین و یادگیری عمیق معرفی شدند که با توجه به رشد روز افزون این حوزه‌ها و مدل‌های پرکاربرد، استفاده‌ی این مدل‌ها در بینایی کامپیوتر و پردازش تصویر بسیار رشد نموده است. بنابراین در این پروژه در نقطه‌ی مشترک حوزه‌های معرفی شده قرار گرفته‌ایم و قصد بر آن است با استفاده از مدل‌های یادگیری عمیق در حوزه‌ی پردازش تصاویر پزشکی، قطعه‌بندی تومور و ساختارهای در ریسک را با دقت و سرعت بالاتر نسبت به الگوریتم‌های پیشین، با ابزارهای معرفی شده، انجام دهیم. در فصل بعد به بررسی و مرور سوابق کارهای انجام شده در حوزه‌ی قطعه‌بندی تصاویر پزشکی پرداخته خواهد شد.